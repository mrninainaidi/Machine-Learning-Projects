{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "personal_loan_default_DL.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "ZWWTMkk2Oc0a",
        "L_bFaWfpx6cr",
        "xsfUBfo9BW-2",
        "iOw1rpi0RPvY",
        "Sd6ARf3lRg6B",
        "YKWrCRKJTm1O"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPX1RhHyr7uSjrzk4SQhFma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrninainaidi/Machine-Learning-Projects/blob/master/personal_loan_default_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7PYWHpONyEv",
        "colab_type": "text"
      },
      "source": [
        "# Preamble\n",
        "\n",
        "* jupyter notebook theme (optional)\n",
        "* package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfayVAP4m1o6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: setup theme for Jupyter Notebook\n",
        "# # comment out if running on Colab\n",
        "# import jupytertheme as jt\n",
        "# from jupyterthemes.stylefx import set_nb_theme\n",
        "\n",
        "# set_nb_theme('chesterish')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qes1W2qBW-xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import xgboost\n",
        "from xgboost import plot_importance\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
        "\n",
        "import gc\n",
        "from scipy import stats\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "!pip install missingno\n",
        "import missingno as msno\n",
        "\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "!pip install imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import seaborn as sns\n",
        "# import altair as alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PCVzJZCvCHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ypXevEy7-Jx",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing and Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOMak_6b8HlT",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWNPSnO5XIf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/further_study/machine_learning_projects/personal_loan_rating/'\n",
        "df = pd.read_csv(root_path+'default_loan_no_quotes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBHP9uTY6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # For others (Jupyter Notebook)\n",
        "# # NOTE: This requies the data file to be saved under the same directory as this file.\n",
        "\n",
        "# df = pd.read_csv('default_loan_no_quotes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQObSRNhey63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBxu5MMavVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = df.columns.str.replace(' ','_')\n",
        "df.columns = map(str.lower, df.columns)\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrVBFnUp8MZd",
        "colab_type": "text"
      },
      "source": [
        "## Features With Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raURiCOxksXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msno.bar(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UV40OxRZcwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "na_names = list()\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].isna().sum() > 0:\n",
        "        print(f'Feature: {col}, has {100 * df[col].isna().sum() / df[col].shape[0]:.3f}%  or {df[col].isna().sum()} null values.')\n",
        "        na_names.append(col)\n",
        "\n",
        "na_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qumnkm98Xbq",
        "colab_type": "text"
      },
      "source": [
        "## Drop the columns of little interests\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP40IhUHm7IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Drop the columns of little interests\n",
        "'''\n",
        "\n",
        "not_interested = ['entry_date', 'fist_installment_date',\\\n",
        "                  'id', 'deposit_amt', 'financed_amt', 'term_remaining',\\\n",
        "                  'instalment_amt', 'amt_paid_to_merchant_nettofmerchfeesandgst',\\\n",
        "                  'est_fees', 'proc_fees', 'other_fees', 'total_merchant_charges',\\\n",
        "                  'total_consumer_charges']\n",
        "\n",
        "for name in not_interested: \n",
        "    if name not in df.columns:\n",
        "        raise ValueError(f'column name: {name} is not valid')\n",
        "\n",
        "df.drop(columns=not_interested, inplace=True)\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lda4tSKq8dCp",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the consumer post code feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dT9M4hZyX3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manually correct typos in post code\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '28501'] = '2850'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '2166`1'] = '2166'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '414'] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == 'CM144WG'] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '4Q53'] = '4053'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '40/2'] = '4012'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '482O'] = '4820'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '500O'] = '5000'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '430('] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '48/7'] = '4817'\n",
        "\n",
        "# convert NA values to 'unknown'\n",
        "consumerid_list = df['consumer_id'].loc[df['consumer_post_code'].isna()].values\n",
        "consumerid_list = set(consumerid_list)\n",
        "print(consumerid_list)\n",
        "\n",
        "for id in consumerid_list:\n",
        "    if df['consumer_post_code'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "        print(f'consumer: {id} has no post code info')\n",
        "        df['consumer_post_code'].loc[df['consumer_id'] == id] = 'unknown'\n",
        "    else:\n",
        "        possible_post_codes = df[\"consumer_post_code\"].loc[df[\"consumer_id\"] == id].values\n",
        "        possible_post_codes = possible_post_codes[pd.notna(possible_post_codes)]\n",
        "        print(f'consumer: {id} has the following post code: {possible_post_codes}')\n",
        "        print(f'    applying post code to consumer: {id}')\n",
        "        df['consumer_post_code'].loc[df['consumer_id'] == id] = str(int(possible_post_codes[0]))\n",
        "\n",
        "\n",
        "# make sure all int and float-type entries are cast to str\n",
        "df['consumer_post_code'] = df['consumer_post_code'].astype(str).replace('\\.0', '', regex=True)\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0B-_RvpFuN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['consumer_post_code'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Q9a0DmLCax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check if all instances of the 'consumer_post_code' feature have been converted\n",
        "# to string-type\n",
        "for _, row in df.iterrows():\n",
        "    try: \n",
        "        assert(isinstance(row['consumer_post_code'], str))\n",
        "    except: \n",
        "        print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHhBDIP8qJb",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the consumer year of birth feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Wp1nG1Mrow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert NA values to '99/99/9999'\n",
        "consumerid_list = df['consumer_id'].loc[df['consumer_year_of_birth'].isna()].values\n",
        "consumerid_list = set(consumerid_list)\n",
        "\n",
        "for id in consumerid_list:\n",
        "    if df['consumer_year_of_birth'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "        print(f'consumer: {id} has no DoB info')\n",
        "        df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = '99/99/9999'\n",
        "    else:\n",
        "        \n",
        "        possibleDoB = df[\"consumer_year_of_birth\"].loc[df[\"consumer_id\"] == id].values\n",
        "        possibleDoB = possibleDoB[pd.notna(possibleDoB)]\n",
        "        print(f'consumer: {id} has the following DoBs: {possibleDoB}')\n",
        "        print(f'    applying DoB to consumer: {id}')\n",
        "        df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = str(possibleDoB[0])\n",
        "\n",
        "# Convert str-type DoB to int-type year of birth\n",
        "df['consumer_year_of_birth'] = df['consumer_year_of_birth'].str.split('/', expand=True)[2].astype(int)\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKO6VKHbWamk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check if all instances of the 'consumer_year_of_birth' feature have been converted\n",
        "# to int-type or np.nan\n",
        "# for _, row in df.iterrows():\n",
        "#     yob = row['consumer_year_of_birth']\n",
        "#     if isinstance(yob, int):\n",
        "#         if yob > 1900 and yob <= 9999:\n",
        "#             continue\n",
        "#     else: \n",
        "#         print(f'row[\"consumer_year_of_birth\"] = {yob}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8_UXd7J91tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['consumer_year_of_birth'].value_counts(normalize=True).sort_index().index\n",
        "y = df['consumer_year_of_birth'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(1900,2000)\n",
        "plt.title('Consumer Age Distribution')\n",
        "plt.xlabel('Year of Birth')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y,'g*')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TiRpV7C8zRl",
        "colab_type": "text"
      },
      "source": [
        "## Converting application_date feature to application_month and application_year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtnZxTUG58ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert str-type application date to int-type year of application\n",
        "df['application_year'] = df['application_date'].str.split('/', expand=True)[2].astype(int)\n",
        "df['application_month'] = df['application_date'].str.split('/', expand=True)[1].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BKv5pbq87QS",
        "colab_type": "text"
      },
      "source": [
        "## Converting recent_default_default_date to recent_default_year and recent_dafault_month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xchjzgDH7oTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['recent_default_default_date'] = df['recent_default_default_date'].replace(np.nan, '00/00/0000', regex=True)\n",
        "df['recent_default_year'] = df['recent_default_default_date'].str.split('/', expand=True)[2].astype(int)\n",
        "df['recent_default_month'] = df['recent_default_default_date'].str.split('/', expand=True)[1].astype(int)\n",
        "# df['recent_default_month'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX1AEV8Tv-FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['recent_default_month'].value_counts(normalize=True).sort_index().index\n",
        "y = df['recent_default_month'].value_counts(normalize=True).sort_index().values\n",
        "\n",
        "plt.xlim(1,12)\n",
        "plt.ylim(0,0.02)\n",
        "\n",
        "plt.title('Recent default month distribution')\n",
        "plt.xlabel('Month of default')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y,'g*-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFyjY--8BZgo",
        "colab_type": "text"
      },
      "source": [
        "## Adding age_of_application feature (integer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieMSSQPBmkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['age_of_application'] = df['application_year'] - df['consumer_year_of_birth']\n",
        "\n",
        "# use this \"age of application\" to validate the \"consumer year of birth\"\n",
        "# if \"age of application\" < 18, the minimum legal age of having a credit account\n",
        "# the \"consumer year of birth\" entry must be faulty. \n",
        "df['consumer_year_of_birth'].loc[df['age_of_application'] < 18] = int(9999)\n",
        "df['age_of_application'].loc[df['age_of_application'] < 18] = int(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rvm4XZtEehR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(df[df['age_of_application'] == -1].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-bQQio2OB-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['age_of_application'].value_counts(normalize=True).sort_index().index\n",
        "y = df['age_of_application'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(-1,100)\n",
        "plt.title('Consumer Age of Application')\n",
        "plt.xlabel('Consumer Age')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y, 'g*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcsXJzCOW3cG",
        "colab_type": "text"
      },
      "source": [
        "## Adding age_of_recent_default feature (integer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GjwBFdAUrf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['age_of_recent_default'] = df['recent_default_year'] - df['consumer_year_of_birth']\n",
        "# df['age_of_recent_default'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYODky0iHMuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recent default should not happen before the year of application\n",
        "# the age of application has to be > 18 for age of recent default to be effective\n",
        "\n",
        "# For invalid entry of recent_default_default_date and consumer_year_of_birth\n",
        "df['age_of_recent_default'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(-1)\n",
        "df['recent_default_year'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(0)\n",
        "df['recent_default_month'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(0)\n",
        "\n",
        "# For absent recent_default_default_date \n",
        "df['age_of_recent_default'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "df['recent_default_year'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "df['recent_default_month'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZQh2iBV6Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['age_of_recent_default'].value_counts(normalize=True).sort_index().index\n",
        "y = df['age_of_recent_default'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(20,100)\n",
        "plt.ylim(0,0.01)\n",
        "plt.title('Consumer Age of Recent Default')\n",
        "plt.xlabel('Consumer Age')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y, 'g*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3KDqO-jfp0D",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning product feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF5ul58lfXpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace NaN with 'unknown'\n",
        "df['product'] = df['product'].replace(np.nan, 'unknown', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq9qS9gOeThc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shorten the tails\n",
        "x = df['product'].value_counts(normalize=True).index\n",
        "y = df['product'].value_counts(normalize=True).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvLoT-zFQ-nW",
        "colab_type": "text"
      },
      "source": [
        "## Shorten the features with heavy tails\n",
        "\n",
        "* 'product'\n",
        "* 'merchant_name'\n",
        "* 'merchant_number'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIL2Bq2dRKqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_tails_to_others(dataframe, feature, fracToConvert):\n",
        "    x = dataframe[feature].value_counts(normalize=True).index\n",
        "    y = dataframe[feature].value_counts(normalize=True).values\n",
        "\n",
        "    all_list = dataframe[feature].value_counts(normalize=True).index.tolist()\n",
        "\n",
        "    # obtain the list of value to keep\n",
        "    threshold = 1 - fracToConvert\n",
        "    current = 0.0\n",
        "    keep_list = list()\n",
        "\n",
        "    for i in range(len(y)):\n",
        "        if current >= threshold:\n",
        "            break\n",
        "        current += y[i]\n",
        "        keep_list.append(x[i])\n",
        "\n",
        "    drop_list = [x for x in all_list if x not in keep_list]\n",
        "\n",
        "    # apply keep_list\n",
        "    dataframe[feature].loc[dataframe[feature].isin(drop_list)] = 'others'\n",
        "    # print(dataframe[feature].value_counts(normalize=True))\n",
        "    # print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUKFo-PQ_b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = ['product', 'merchant_name', 'merchant_number']\n",
        "frac_dict = {'product':0.08, 'merchant_name':0.05, 'merchant_number':0.05}\n",
        "\n",
        "for name in col_names:\n",
        "    convert_tails_to_others(df, name, frac_dict[name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiU-haX6xIm",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning total_balance_outstanding feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgd-Iy4f14iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = df['total_balance_outstanding']\n",
        "\n",
        "df_tmp.replace(np.nan, '0.0', regex=True, inplace=True)\n",
        "df_tmp.replace(',', '', regex=True, inplace=True)\n",
        "df_tmp = df_tmp.astype(float)\n",
        "\n",
        "df['total_balance_outstanding'] = df_tmp\n",
        "del df_tmp\n",
        "print('Convertion complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHU-Iqef5QDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # check if everything has been converted to float-type\n",
        "# for index, value in df['total_balance_outstanding'].items():\n",
        "#     if not isinstance(value, float):\n",
        "#         print(f'{value} ----- {type(value)}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K93H3sfut1Ij",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning recent_default_default_amt feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNC2_s-yt5hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = df['recent_default_default_amt']\n",
        "\n",
        "df_tmp.replace(np.nan, '0.0', regex=True, inplace=True)\n",
        "df_tmp.replace(',', '', regex=True, inplace=True)\n",
        "df_tmp = df_tmp.astype(float)\n",
        "\n",
        "df['recent_default_default_amt'] = df_tmp\n",
        "del df_tmp\n",
        "print('Convertion complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Dt0Sy4uiRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # check if everything has been converted to float-type\n",
        "# for index, value in df['recent_default_default_amt'].items():\n",
        "#     if not isinstance(value, float):\n",
        "#         print(f'{value} ----- {type(value)}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAeieMjhXlQb",
        "colab_type": "text"
      },
      "source": [
        "## Adding term_run_frac feature\n",
        "representing the fraction of terms that have been fulfilled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApB0LChyXkWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['term_run_frac'] = df['term_run'] / df['total_term']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1hUvZKv9JAS",
        "colab_type": "text"
      },
      "source": [
        "## Adding total_month feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jFde3zR9Ird",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = pd.DataFrame()\n",
        "df_tmp['total_term'] = df['total_term']\n",
        "df_tmp['total_month'] = df['total_term']\n",
        "df_tmp['freq'] = df['freq']\n",
        "\n",
        "mask = (df_tmp['freq'] == 'FN')\n",
        "df_valid = df_tmp[mask]\n",
        "\n",
        "df_tmp.loc[mask, 'total_month'] = df_valid['total_term'] / 2\n",
        "\n",
        "df['total_month'] = df_tmp['total_month']\n",
        "del df_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyGDovP3Dasn",
        "colab_type": "text"
      },
      "source": [
        "## Adding conditional mean/std features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvwm6TDODYp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conditioning for \"age_op_application\"\n",
        "df['aop_indName_mean'] = df['age_of_application'] / df.groupby(['industry_name'])['age_of_application'].transform('mean')\n",
        "df['aop_indName_stdev'] = df['age_of_application'] / df.groupby(['industry_name'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_pmtTp_mean'] = df['age_of_application'] / df.groupby(['payment_type'])['age_of_application'].transform('mean')\n",
        "df['aop_pmtTp_stdev'] = df['age_of_application'] / df.groupby(['payment_type'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_fq_mean'] = df['age_of_application'] / df.groupby(['freq'])['age_of_application'].transform('mean')\n",
        "df['aop_fq_stdev'] = df['age_of_application'] / df.groupby(['freq'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_hoId_mean'] = df['age_of_application'] / df.groupby(['homowner_ind'])['age_of_application'].transform('mean')\n",
        "df['aop_hoId_stdev'] = df['age_of_application'] / df.groupby(['homowner_ind'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_hoCon_mean'] = df['age_of_application'] / df.groupby(['homowner_consumer'])['age_of_application'].transform('mean')\n",
        "df['aop_hoCon_stdev'] = df['age_of_application'] / df.groupby(['homowner_consumer'])['age_of_application'].transform('std')\n",
        "\n",
        "\n",
        "# Conditioning for \"purchase_amt\"\n",
        "df['pAmt_indName_mean'] = df['purchase_amt'] / df.groupby(['industry_name'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_indName_stdev'] = df['purchase_amt'] / df.groupby(['industry_name'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_pmtTp_mean'] = df['purchase_amt'] / df.groupby(['payment_type'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_pmtTp_stdev'] = df['purchase_amt'] / df.groupby(['payment_type'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_fq_mean'] = df['purchase_amt'] / df.groupby(['freq'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_fq_stdev'] = df['purchase_amt'] / df.groupby(['freq'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_hoId_mean'] = df['purchase_amt'] / df.groupby(['homowner_ind'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_hoId_stdev'] = df['purchase_amt'] / df.groupby(['homowner_ind'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_hoCon_mean'] = df['purchase_amt'] / df.groupby(['homowner_consumer'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_hoCon_stdev'] = df['purchase_amt'] / df.groupby(['homowner_consumer'])['purchase_amt'].transform('std')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfWv18HukSQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(df[df['aop_indName_stdev'].isna()].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHo3kAh5klR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check for NaN in the conditional features: \n",
        "cond_names = ['aop_indName_mean', 'aop_indName_stdev', 'aop_pmtTp_mean',\\\n",
        "              'aop_pmtTp_stdev', 'aop_fq_mean', 'aop_fq_stdev', 'aop_hoId_mean',\\\n",
        "              'aop_hoId_stdev', 'aop_hoCon_mean', 'aop_hoCon_stdev', 'pAmt_indName_mean',\\\n",
        "              'pAmt_indName_stdev', 'pAmt_pmtTp_mean', 'pAmt_pmtTp_stdev', 'pAmt_fq_mean',\\\n",
        "              'pAmt_fq_stdev', 'pAmt_hoId_mean', 'pAmt_hoId_stdev', 'pAmt_hoCon_mean', 'pAmt_hoCon_stdev']\n",
        "\n",
        "df_tmp = pd.DataFrame()\n",
        "for name in cond_names:\n",
        "    df_tmp[name] = df[name].copy()\n",
        "\n",
        "# df_tmp.head()\n",
        "msno.bar(df_tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX4sewp5DNa9",
        "colab_type": "text"
      },
      "source": [
        "## Define ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdivUjVfNekc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_recent = df[[col for col in df.columns if 'recent' in col]]\n",
        "# df_recent['defaultdate'] = df['defaultdate']\n",
        "# df_recent['consumer_id'] = df['consumer_id']\n",
        "# df_recent['defaultamount'] = df['defaultamount']\n",
        "# df_recent['contract_number'] = df['contract_number']\n",
        "# df_recent['contract_status'] = df['contract_status']\n",
        "# df_recent['expected_contract_end_date'] = df['expected_contract_end_date']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcQTEsynm_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in df_recent.iterrows():\n",
        "#     if row['recent_default_default_amt'] == 0:\n",
        "#         if isinstance(row['defaultdate'], str):\n",
        "#             print(row)\n",
        "#             print()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U_bCUCS_asC",
        "colab_type": "text"
      },
      "source": [
        "**Test outcome**\n",
        "\n",
        "* when \"recent_default_year\" == 0, there are FIVE instances that \"recent_default_default_amt\" != 0. And all FIVE instances are marked as DEFAULT by the \"contract_status\"\n",
        "\n",
        "\n",
        "* when \"recent_default_default_amt\" == 0, there are TWO instances that \"recent_default_year\" != 0. And all of the TWO instances are marked as PAIDINFULL by the \"contract_status\".\n",
        "\n",
        "    ==> both \"recent_default_year\" and \"recent_default_default_amt\" == 0 means NoDefault\n",
        "\n",
        "**Suspect bad columns:**\n",
        "\n",
        "Assumning 'recent_default_default_amt' is the indicator for the ground truth... \n",
        "\n",
        "* 'defaultdate'\n",
        "\n",
        "* 'defaultamount'\n",
        "\n",
        "* 'total_balance_outstanding'\n",
        "\n",
        "* 'recent_default_default_date' ==> 'recent_default_year' ==> 'recent_default_age'\n",
        "\n",
        "\n",
        "**Question:**\n",
        "\n",
        "Do I go back to realign 'recent_default_year' and 'recent_default_age' with the assumed ground truth???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ingd24T6LmEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# introduce the ground truth according to above analysis\n",
        "df['isDefault'] = df['recent_default_default_amt'] > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn703GRTL9Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # to check\n",
        "# for index, row in df.iterrows():\n",
        "#     if row['recent_default_default_amt'] > 0:\n",
        "#         if df['isDefault'] is False:\n",
        "#             print(row)\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ZFyqU-_zNT",
        "colab_type": "text"
      },
      "source": [
        "## Finalising data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRiOwCVFUTWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmmbFwP4Ii31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEiwLvozYjJR",
        "colab_type": "text"
      },
      "source": [
        "### Collect the input columns of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciFpgBiTdiSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cols = ['purchase_amt', 'deposit_percent', 'gtee_rate', 'term_run_frac', 'total_month']\n",
        "num_cols = num_cols + cond_names\n",
        "\n",
        "buk_cols = ['age_of_application']\n",
        "\n",
        "ind_cols = ['application_year', 'application_month', 'payment_type', 'freq', 'homowner_ind', 'homowner_consumer']\n",
        "\n",
        "emb_cols = ['product', 'consumer_post_code', 'industry_name', 'merchant_number']\n",
        "\n",
        "tar_cols = ['isDefault']\n",
        "\n",
        "all_cols = num_cols + buk_cols + ind_cols + emb_cols + tar_cols\n",
        "\n",
        "# populate df_train\n",
        "df_train = pd.DataFrame()\n",
        "for col in all_cols:\n",
        "    df_train[col] = df[col].copy()\n",
        "\n",
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GIxKR7Wjy3vr"
      },
      "source": [
        "### Digitise all **'object'** type columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUFhTzbry3vs",
        "colab": {}
      },
      "source": [
        "for col in df_train.columns:\n",
        "    if df_train[col].dtypes == 'object' or df_train[col].dtypes == 'bool':\n",
        "        df_train[col] = pd.Categorical(df_train[col])\n",
        "        df_train[col] = df_train[col].cat.codes\n",
        "\n",
        "    if df_train[col].dtypes == 'float64':\n",
        "        df_train[col] = df_train[col].astype(np.float32)\n",
        "\n",
        "df_train.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkIPQ2dDseuO",
        "colab_type": "text"
      },
      "source": [
        "### Re-sampling with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxIZyRdsfJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model input\n",
        "X = df_train.drop(columns=['isDefault'])\n",
        "\n",
        "# expected output\n",
        "y = df_train['isDefault']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3wuiUh4suiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialise SMOTE sampling\n",
        "sm = SMOTE(random_state=RAND_STATE)\n",
        "\n",
        "# resample the training set\n",
        "input, target = sm.fit_sample(X, y.ravel())\n",
        "print(target.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbIqMP8-swqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = pd.DataFrame(input, columns=X.columns)\n",
        "df_tmp['isDefault'] = target\n",
        "df_tmp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4ZHiphvxqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_tmp\n",
        "del df_tmp\n",
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLXWNJ44ANOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cast some features to int-type for encoding\n",
        "for col in df_train.columns:\n",
        "    if col in ind_cols or col in emb_cols:\n",
        "        df_train[col] = df_train[col].astype(np.int32)\n",
        "    elif col in num_cols or col in buk_cols: \n",
        "        df_train[col] = df_train[col].astype(np.float32)\n",
        "\n",
        "df_train.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT8QMEqkba-3",
        "colab_type": "text"
      },
      "source": [
        "### Split the dataframe into train, test, and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPb6spb6VHKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(df_train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXdnfDCkW8Pr",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOw1rpi0RPvY",
        "colab_type": "text"
      },
      "source": [
        "## Input Pipeline Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd6ARf3lRg6B",
        "colab_type": "text"
      },
      "source": [
        "### Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWiB5O8ZUbw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Utility functions definition\n",
        "'''\n",
        "# normalising numerical features\n",
        "def get_scal(feature):\n",
        "  def minmax(x):\n",
        "    mini = train[feature].min()\n",
        "    maxi = train[feature].max()\n",
        "    return (x - mini)/(maxi-mini)\n",
        "  return(minmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFVywF9Rmmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# Numerical columns\n",
        "for feature_name in num_cols:\n",
        "  scal_input_fn = get_scal(feature_name)\n",
        "  feature_columns.append(feature_column.numeric_column(feature_name, normalizer_fn=scal_input_fn))\n",
        "\n",
        "# Bucketized columns\n",
        "for feature_name in buk_cols:\n",
        "    # only one feature in the buk_cols ==> age of application\n",
        "    age_boundaries = [18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105]\n",
        "    Age = feature_column.numeric_column(feature_name)\n",
        "    age_buckets = feature_column.bucketized_column(Age, boundaries=age_boundaries)\n",
        "    feature_columns.append(age_buckets)\n",
        "\n",
        "# Categorical indicator columns\n",
        "for feature_name in ind_cols:\n",
        "  vocabulary = df_train[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  one_hot = feature_column.indicator_column(cat_c)\n",
        "  feature_columns.append(one_hot)\n",
        "\n",
        "# Categorical embedding columns\n",
        "for feature_name in emb_cols:\n",
        "  vocabulary = df_train[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  embeding = feature_column.embedding_column(cat_c, dimension=50)\n",
        "  feature_columns.append(embeding)\n",
        "\n",
        "len(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKWrCRKJTm1O",
        "colab_type": "text"
      },
      "source": [
        "### Create the input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqRwCuJ41sgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('isDefault')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g00jlNmi4u3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Testing the input pipeline\n",
        "\n",
        "# batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "# train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "# val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "# test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "# for feature_batch, label_batch in train_ds.take(1):\n",
        "#   print('Every feature:', list(feature_batch.keys()))\n",
        "#   print('A batch of merchant_number:', feature_batch['merchant_number'])\n",
        "#   print('A batch of targets:', label_batch )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UQzqWueW_H3",
        "colab_type": "text"
      },
      "source": [
        "## Create & Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWiNjILDXBQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "    #   tf.keras.metrics.Precision(name='precision'),\n",
        "    #   tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'), \n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn')\n",
        "]\n",
        "\n",
        "def create_and_compile_nn(feature_columns, optimiser, hl1, hl1_act,  hl2=0, hl2_act=''):\n",
        "\n",
        "    # Create a input-feature layer\n",
        "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "    # Assemble the model\n",
        "    # model = tf.keras.Sequential([\n",
        "    # feature_layer,\n",
        "    # layers.Dense(hl1, activation=hl1_act),\n",
        "    # layers.Dense(hl2, activation=hl2_act),\n",
        "    # layers.Dropout(.1),\n",
        "    # layers.Dense(1)\n",
        "    # ])\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(feature_layer)\n",
        "    model.add(tf.keras.layers.Dense(units=hl1, activation=hl1_act))\n",
        "\n",
        "    if not hl2 == 0:\n",
        "        model.add(tf.keras.layers.Dense(units=hl2, activation=hl2_act))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(.1))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=METRICS)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "829U7fkXFpuY",
        "colab_type": "text"
      },
      "source": [
        "## Training & Evaluation\n",
        "with\n",
        "\n",
        "* cross validation\n",
        "* hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCCIQ3pfFu-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(params):\n",
        "    time1 = time.time()\n",
        "\n",
        "    params = {\n",
        "        'hl1'       : int(params['hl1']),\n",
        "        'hl1_act'   : str(params['hl1_act']), \n",
        "        'hl2'       : int(params['hl2']),\n",
        "        'hl2_act'   : str(params['hl2_act']), \n",
        "        'optimiser' : str(params['optimiser'])\n",
        "    }\n",
        "\n",
        "    df_toprint = pd.DataFrame(params, index=[0])\n",
        "\n",
        "    print('\\n############## New Run ################')\n",
        "    print(f\"params = {df_toprint.transpose()}\")\n",
        "\n",
        "    # set the number of epochs\n",
        "    n_epochs = 6\n",
        "\n",
        "    # tmp batch_size\n",
        "    tmp_batch_size = 2048\n",
        "\n",
        "    # obtain the testing set\n",
        "    test_ds = df_to_dataset(test, shuffle=False, batch_size=tmp_batch_size)\n",
        "        \n",
        "    # declair total number of folds and fold counter\n",
        "    FOLDS = 3\n",
        "    counter = 1\n",
        "\n",
        "    # instantiate the TSS model\n",
        "    skf = KFold(n_splits=FOLDS, shuffle=True, random_state=RAND_STATE)\n",
        "    cv_accuracy = []\n",
        "    cv_auc = []\n",
        "\n",
        "    print(f'\\nTraining set shape: {train.shape}')\n",
        "\n",
        "    # Start the Training and Cross-validation loop\n",
        "    for t_idx, v_idx in skf.split(train):\n",
        "        print(f'\\nRunning Fold No.: {counter}... ')\n",
        "        # get the split dataframes\n",
        "        X_t, X_v = train.iloc[t_idx, :], train.iloc[v_idx, :]\n",
        "\n",
        "        # convert to TF datasets\n",
        "        train_ds = df_to_dataset(X_t, shuffle=True, batch_size=tmp_batch_size)   \n",
        "        val_ds = df_to_dataset(X_v, shuffle=True, batch_size=tmp_batch_size)  \n",
        "\n",
        "        # Model definition\n",
        "        model = create_and_compile_nn(feature_columns, \n",
        "                                      **params)\n",
        "\n",
        "        # Model training\n",
        "        model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=n_epochs,\n",
        "                    verbose=2)\n",
        "\n",
        "        # evaluate the model\n",
        "        scores = model.evaluate(test_ds, verbose=0)\n",
        "\n",
        "        print(f\"\\nModel accuracy = {model.metrics_names[1], round((scores[1]*100), 4)}%\")\n",
        "        cv_accuracy.append(scores[1])\n",
        "        cv_auc.append(scores[2])\n",
        "\n",
        "        counter += 1\n",
        "    \n",
        "    # record the time elapsed\n",
        "    time2 = time.time() - time1\n",
        "    print(f\"Total Time Run: {round(time2 / 60,2)} mins\")\n",
        "\n",
        "    gc.collect() # garbage collection\n",
        "    print('\\nTesting results: ')\n",
        "    print(f\"Average model accuracy = {round(np.mean(cv_accuracy), 4)}\")\n",
        "    print(f\"Average model AUC = {round(np.mean(cv_auc), 4)}\")\n",
        "\n",
        "    del X_t, X_v, scores\n",
        "\n",
        "    # optimise parameter search with model accuracy\n",
        "    return -(np.mean(cv_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfzrizRYylr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# space = {\n",
        "#     'hl1' : hp.choice('hl1', list(range(8,32,2))), \n",
        "#     'hl1_act' : hp.choice('hl1_act', ['relu']),\n",
        "#     'hl2' : hp.choice('hl2', [0]), \n",
        "#     'hl2_act' : hp.choice('hl2_act', ['relu', 'sigmoid']),  \n",
        "#     'optimiser' : hp.choice('optimiser', ['adam']) \n",
        "# }\n",
        "\n",
        "# Dummy space\n",
        "space = {\n",
        "    'hl1' : hp.choice('hl1', [32]), \n",
        "    'hl1_act' : hp.choice('hl1_act', ['relu']),\n",
        "    'hl2' : hp.choice('hl2', [0]), \n",
        "    'hl2_act' : hp.choice('hl2_act', ['relu', 'sigmoid']),  \n",
        "    'optimiser' : hp.choice('optimiser', ['adam']) \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE2WOb-Gzqtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set algoritm parameters\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=1)\n",
        "\n",
        "print('Done optimising')\n",
        "\n",
        "# Print best parameters\n",
        "best_params = space_eval(space, best)\n",
        "\n",
        "# print(\"BEST PARAMS: \", best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQ87b_NUrgw",
        "colab_type": "text"
      },
      "source": [
        "# Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TW4r9xnORKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simulation stops HERE\n",
        "raise SystemExit('Run Terminated.') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVi5g5q4DUdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "0. Original model\n",
        "================================================================================\n",
        "Testing scores: \n",
        "Average model accuracy = 0.8542\n",
        "Average model AUC = 0.5\n",
        "\n",
        "\n",
        "1. SMOTE\n",
        "================================================================================\n",
        "Testing results: \n",
        "Average model accuracy = 0.7824\n",
        "Average model AUC = 0.8253\n",
        "\n",
        "\n",
        "2. Conditional features\n",
        "================================================================================\n",
        "Testing results: \n",
        "Average model accuracy = 0.8571\n",
        "Average model AUC = 0.5001\n",
        "\n",
        "\n",
        "3. 1 + 2\n",
        "================================================================================\n",
        "Testing results: \n",
        "Average model accuracy = 0.7805\n",
        "Average model AUC = 0.8257\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGaTCyhUcaY9",
        "colab_type": "text"
      },
      "source": [
        "# Code Dump"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuvGOcaKVxLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def objective(params):\n",
        "#     time1 = time.time()\n",
        "\n",
        "#     params = {\n",
        "#         'hl1'       : int(params['hl1']),\n",
        "#         'hl1_act'   : str(params['hl1_act']), \n",
        "#         'hl2'       : int(params['hl2']),\n",
        "#         'hl2_act'   : str(params['hl2_act']), \n",
        "#         'optimiser' : str(params['optimiser'])\n",
        "#     }\n",
        "\n",
        "#     df_toprint = pd.DataFrame(params, index=[0])\n",
        "\n",
        "#     print('\\n############## New Run ################')\n",
        "#     print(f\"params = {df_toprint.transpose()}\")\n",
        "\n",
        "#     # set the number of epochs\n",
        "#     n_epochs = 6\n",
        "\n",
        "#     # tmp batch_size\n",
        "#     tmp_batch_size = 500\n",
        "\n",
        "#     # obtain the testing set\n",
        "#     test_ds = df_to_dataset(test, shuffle=False, batch_size=1)\n",
        "        \n",
        "#     # declair total number of folds and fold counter\n",
        "#     FOLDS = 6\n",
        "#     counter = 1\n",
        "\n",
        "#     # instantiate the TSS model\n",
        "#     skf = KFold(n_splits=FOLDS, shuffle=True, random_state=RAND_STATE)\n",
        "#     cvscores = []\n",
        "\n",
        "#     print(f'\\nTraining set shape: {train.shape}')\n",
        "\n",
        "#     # Start the Training and Cross-validation loop\n",
        "#     for t_idx, v_idx in skf.split(train):\n",
        "#         print(f'\\nRunning Fold No.: {counter}... ')\n",
        "#         # get the split dataframes\n",
        "#         X_t, X_v = train.iloc[t_idx, :], train.iloc[v_idx, :]\n",
        "\n",
        "#         # convert to TF datasets\n",
        "#         train_ds = df_to_dataset(X_t, shuffle=False, batch_size=tmp_batch_size)   \n",
        "#         val_ds = df_to_dataset(X_v, shuffle=False, batch_size=tmp_batch_size)  \n",
        "\n",
        "#         # Model definition\n",
        "#         model = create_and_compile_nn(feature_columns, \n",
        "#                                       **params)\n",
        "\n",
        "#         # Model training\n",
        "#         model.fit(train_ds,\n",
        "#                     validation_data=val_ds,\n",
        "#                     epochs=n_epochs,\n",
        "#                     verbose=2)\n",
        "\n",
        "#         # evaluate the model\n",
        "#         scores = model.evaluate(test_ds)\n",
        "\n",
        "#         print(f\"\\nModel accuracy = {model.metrics_names[1], scores[1]*100}\")\n",
        "#         cvscores.append(scores[1] * 100)\n",
        "\n",
        "#         counter += 1\n",
        "    \n",
        "#     # record the time elapsed\n",
        "#     time2 = time.time() - time1\n",
        "#     print(f\"Total Time Run: {round(time2 / 60,2)} mins\")\n",
        "\n",
        "\n",
        "#     gc.collect() # garbage collection\n",
        "#     print(f\"\\nAverage model accuracy = {np.mean(cvscores)} +/- {np.std(cvscores)}\")\n",
        "\n",
        "#     del X_t, X_v, scores\n",
        "\n",
        "#     return -(np.mean(cvscores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWWTMkk2Oc0a",
        "colab_type": "text"
      },
      "source": [
        "## Exploring other features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_bFaWfpx6cr",
        "colab_type": "text"
      },
      "source": [
        "### Exploring arrears amount feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriQX94hg12n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = df['arrears_amount'].value_counts(dropna=False).sort_index()\n",
        "# print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2K1Z-ujhRRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_tmp = df.loc[ df['arrears_amount'] == 0]\n",
        "# df_tmp['contract_status'].value_counts(normalize=True, dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsfUBfo9BW-2",
        "colab_type": "text"
      },
      "source": [
        "### Exploring contract_status feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym-oyOxCj-3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# '''\n",
        "# Separate the dataframe by contract status\n",
        "# '''\n",
        "\n",
        "# df_paid = df.loc[df['contract_status'] == 'PaidInFull']\n",
        "# df_default = df.loc[df['contract_status'] == 'Default']\n",
        "# df_active = df.loc[df['contract_status'] == 'Active']\n",
        "# print(df['contract_status'].value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RRPEgCcla7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the Paid-set\n",
        "# # '''\n",
        "# print(df_paid['arrears_amount'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_paid['age_of_recent_default'].value_counts(dropna=False, normalize=False).sort_index())\n",
        "# print()\n",
        "# print(df_paid['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_paid['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_paid['term_run'] / df_paid['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7q9APt-SSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the Default-set\n",
        "# # '''\n",
        "# print(df_default['arrears_amount'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['age_of_recent_default'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_default['term_run'] / df_default['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYchalKIAFhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the active-set\n",
        "# # '''\n",
        "# print(df_active['arrears_amount'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['age_of_recent_default'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_active['term_run'] / df_active['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vooTQ19Aqld",
        "colab_type": "text"
      },
      "source": [
        "**My Questions regarding the \"contract_status\" feature (ground-truth?)**\n",
        "\n",
        "* All instances in \"PaidInFull\" subset have 0.0 \"arrears_amount\", but more than 10% of the instances in this subset has a valid \"age_of_recent_default\", which suggests default did occur to these intances. All instances in this subset have NaN value for \"defaultdate\"\n",
        "\n",
        "* About 3% of the instances in \"Default\" subset have 0.0 \"arrears_amount\", which indicate default has never occured to these instances. 99.7% of this subset have a valid \"defaultdate\" entry.\n",
        "\n",
        "* \"Active\" subset has very similar behaviour when compared against \"PaidInFull\". All instances in this subset have NaN value for \"defaultdate\"\n",
        "\n",
        "**Options for ground-truth**\n",
        "\n",
        "If **True** ==> has default, **False** ==> has no default: \n",
        "\n",
        "1. **True** = \"Default\" subset and **False** = \"PaidInFull\" + \"Active\" subsets\n",
        "\n",
        "2. **True** = \"arrears_amount\" != 0, and **False** = \"arrears_amount\" == 0\n",
        "\n",
        "3. **True** = \"defaultdate\" == valid date, and **False** = NaN\n",
        "\n",
        "**According to the observations, none of the above options are fully make sense...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjQaKNxcQhVf",
        "colab_type": "text"
      },
      "source": [
        "**Meeting outcome**\n",
        "\n",
        "\n",
        "4. use the combined recent group to determine the ground truth. \n",
        "\n",
        "    i.e. when \"age_of_recent_default\", \"age_of_recent_default_cure\" and \"recent_default_amt\" are all valid ==> **DEFAULT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpZTuifNAu4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# # Parameters\n",
        "# learning_rate = 0.01\n",
        "# batch_size = 500\n",
        "\n",
        "# # TF graph\n",
        "# x = tf.placeholder(tf.float32, [None, 784])\n",
        "# y = tf.placeholder(tf.float32, [None, 10])\n",
        "# W = tf.Variable(tf.zeros([784, 10]))\n",
        "# b = tf.Variable(tf.zeros([10]))\n",
        "# pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "# cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
        "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "# correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# init = tf.global_variables_initializer()\n",
        "\n",
        "# mnist = input_data.read_data_sets(\"data/mnist-tf\", one_hot=True)\n",
        "# train_x_all = mnist.train.images\n",
        "# train_y_all = mnist.train.labels\n",
        "# test_x = mnist.test.images\n",
        "# test_y = mnist.test.labels\n",
        "\n",
        "# def run_train(session, train_x, train_y):\n",
        "#   print \"\\nStart training\"\n",
        "#   session.run(init)\n",
        "#   for epoch in range(10):\n",
        "#     total_batch = int(train_x.shape[0] / batch_size)\n",
        "#     for i in range(total_batch):\n",
        "#       batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
        "#       batch_y = train_y[i*batch_size:(i+1)*batch_size]\n",
        "#       _, c = session.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
        "#       if i % 50 == 0:\n",
        "#         print \"Epoch #%d step=%d cost=%f\" % (epoch, i, c)\n",
        "\n",
        "# def cross_validate(session, split_size=5):\n",
        "#   results = []\n",
        "#   kf = KFold(n_splits=split_size)\n",
        "#   for train_idx, val_idx in kf.split(train_x_all, train_y_all):\n",
        "#     train_x = train_x_all[train_idx]\n",
        "#     train_y = train_y_all[train_idx]\n",
        "#     val_x = train_x_all[val_idx]\n",
        "#     val_y = train_y_all[val_idx]\n",
        "#     run_train(session, train_x, train_y)\n",
        "#     results.append(session.run(accuracy, feed_dict={x: val_x, y: val_y}))\n",
        "#   return results\n",
        "\n",
        "# with tf.Session() as session:\n",
        "#   result = cross_validate(session)\n",
        "#   print \"Cross-validation result: %s\" % result\n",
        "#   print \"Test accuracy: %f\" % session.run(accuracy, feed_dict={x: test_x, y: test_y})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gExdtYgLXiQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n_epochs = 10\n",
        "# batch_size_train = train.shape[0] // n_epochs\n",
        "\n",
        "# train_ds = df_to_dataset(train, shuffle=False, batch_size=batch_size_train)\n",
        "\n",
        "# test_ds = df_to_dataset(test, shuffle=False, batch_size=test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpWDUCI7eW89",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvo_Z8LXeax_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(train_ds,\n",
        "#           validation_data=val_ds,\n",
        "#           epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om3sDYkOessz",
        "colab_type": "text"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QXxvTHCelOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_ds = df_to_dataset(test, shuffle=False, batch_size=test.shape[0])\n",
        "\n",
        "# loss, accuracy = model.evaluate(test_ds)\n",
        "# print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}