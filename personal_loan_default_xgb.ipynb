{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "personal_loan_default_xgb.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "c7PYWHpONyEv",
        "HGaTCyhUcaY9",
        "ZWWTMkk2Oc0a",
        "L_bFaWfpx6cr",
        "xsfUBfo9BW-2"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/JcwDKRUic7UhoiQRAngW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrninainaidi/Machine-Learning-Projects/blob/master/personal_loan_default_xgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7PYWHpONyEv",
        "colab_type": "text"
      },
      "source": [
        "# Preamble\n",
        "\n",
        "* jupyter notebook theme (optional)\n",
        "* package\n",
        "* global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfayVAP4m1o6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Optional: setup theme for Jupyter Notebook\n",
        "# # comment out if running on Colab\n",
        "# import jupytertheme as jt\n",
        "# from jupyterthemes.stylefx import set_nb_theme\n",
        "\n",
        "# set_nb_theme('chesterish')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qes1W2qBW-xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "import xgboost\n",
        "from xgboost import plot_importance\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
        "\n",
        "import gc\n",
        "from scipy import stats\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "!pip install missingno\n",
        "import missingno as msno\n",
        "\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "!pip install imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# import seaborn as sns\n",
        "# import altair as alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2hO-Pg9baks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ypXevEy7-Jx",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing and Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOMak_6b8HlT",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWNPSnO5XIf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/further_study/machine_learning_projects/personal_loan_rating/'\n",
        "df = pd.read_csv(root_path+'default_loan_no_quotes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBHP9uTY6H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # For others (Jupyter Notebook)\n",
        "# # NOTE: This requies the data file to be saved under the same directory as this file.\n",
        "\n",
        "# df = pd.read_csv('default_loan_no_quotes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQObSRNhey63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBxu5MMavVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = df.columns.str.replace(' ','_')\n",
        "df.columns = map(str.lower, df.columns)\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrVBFnUp8MZd",
        "colab_type": "text"
      },
      "source": [
        "## Features With Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p8VSdXTBcw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msno.bar(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UV40OxRZcwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "na_names = list()\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].isna().sum() > 0:\n",
        "        print(f'Feature: {col}, has {100 * df[col].isna().sum() / df[col].shape[0]:.3f}%  or {df[col].isna().sum()} null values.')\n",
        "        na_names.append(col)\n",
        "\n",
        "na_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9YkaaLE8SR4",
        "colab_type": "text"
      },
      "source": [
        "## Checking Feature Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qumnkm98Xbq",
        "colab_type": "text"
      },
      "source": [
        "## Drop the columns of little interests\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP40IhUHm7IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Drop the columns of little interests\n",
        "'''\n",
        "\n",
        "not_interested = ['entry_date', 'fist_installment_date',\\\n",
        "                  'id', 'deposit_amt', 'financed_amt', 'term_remaining',\\\n",
        "                  'instalment_amt', 'amt_paid_to_merchant_nettofmerchfeesandgst',\\\n",
        "                  'est_fees', 'proc_fees', 'other_fees', 'total_merchant_charges',\\\n",
        "                  'total_consumer_charges']\n",
        "\n",
        "for name in not_interested: \n",
        "    if name not in df.columns:\n",
        "        raise ValueError(f'column name: {name} is not valid')\n",
        "\n",
        "df.drop(columns=not_interested, inplace=True)\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lda4tSKq8dCp",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the consumer post code feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dT9M4hZyX3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manually correct typos in post code\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '28501'] = '2850'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '2166`1'] = '2166'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '414'] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == 'CM144WG'] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '4Q53'] = '4053'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '40/2'] = '4012'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '482O'] = '4820'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '500O'] = '5000'\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '430('] = np.nan\n",
        "df['consumer_post_code'].loc[df['consumer_post_code'] == '48/7'] = '4817'\n",
        "\n",
        "# convert NA values to 'unknown'\n",
        "consumerid_list = df['consumer_id'].loc[df['consumer_post_code'].isna()].values\n",
        "consumerid_list = set(consumerid_list)\n",
        "print(consumerid_list)\n",
        "\n",
        "for id in consumerid_list:\n",
        "    if df['consumer_post_code'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "        print(f'consumer: {id} has no post code info')\n",
        "        df['consumer_post_code'].loc[df['consumer_id'] == id] = 'unknown'\n",
        "    else:\n",
        "        possible_post_codes = df[\"consumer_post_code\"].loc[df[\"consumer_id\"] == id].values\n",
        "        possible_post_codes = possible_post_codes[pd.notna(possible_post_codes)]\n",
        "        print(f'consumer: {id} has the following post code: {possible_post_codes}')\n",
        "        print(f'    applying post code to consumer: {id}')\n",
        "        df['consumer_post_code'].loc[df['consumer_id'] == id] = str(int(possible_post_codes[0]))\n",
        "\n",
        "\n",
        "# make sure all int and float-type entries are cast to str\n",
        "df['consumer_post_code'] = df['consumer_post_code'].astype(str).replace('\\.0', '', regex=True)\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Q9a0DmLCax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # to check if all instances of the 'consumer_post_code' feature have been converted\n",
        "# # to string-type\n",
        "# for _, row in df.iterrows():\n",
        "#     try: \n",
        "#         assert(isinstance(row['consumer_post_code'], str))\n",
        "#     except: \n",
        "#         print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHhBDIP8qJb",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning the consumer year of birth feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Wp1nG1Mrow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert NA values to '99/99/9999'\n",
        "consumerid_list = df['consumer_id'].loc[df['consumer_year_of_birth'].isna()].values\n",
        "consumerid_list = set(consumerid_list)\n",
        "\n",
        "for id in consumerid_list:\n",
        "    if df['consumer_year_of_birth'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "        print(f'consumer: {id} has no DoB info')\n",
        "        df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = '99/99/9999'\n",
        "    else:\n",
        "        \n",
        "        possibleDoB = df[\"consumer_year_of_birth\"].loc[df[\"consumer_id\"] == id].values\n",
        "        possibleDoB = possibleDoB[pd.notna(possibleDoB)]\n",
        "        print(f'consumer: {id} has the following DoBs: {possibleDoB}')\n",
        "        print(f'    applying DoB to consumer: {id}')\n",
        "        df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = str(possibleDoB[0])\n",
        "\n",
        "# Convert str-type DoB to int-type year of birth\n",
        "df['consumer_year_of_birth'] = df['consumer_year_of_birth'].str.split('/', expand=True)[2].astype(int)\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKO6VKHbWamk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check if all instances of the 'consumer_year_of_birth' feature have been converted\n",
        "# to int-type or np.nan\n",
        "# for _, row in df.iterrows():\n",
        "#     yob = row['consumer_year_of_birth']\n",
        "#     if isinstance(yob, int):\n",
        "#         if yob > 1900 and yob <= 9999:\n",
        "#             continue\n",
        "#     else: \n",
        "#         print(f'row[\"consumer_year_of_birth\"] = {yob}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8_UXd7J91tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['consumer_year_of_birth'].value_counts(normalize=True).sort_index().index\n",
        "y = df['consumer_year_of_birth'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(1900,2000)\n",
        "plt.title('Consumer Age Distribution')\n",
        "plt.xlabel('Year of Birth')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y,'g*')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TiRpV7C8zRl",
        "colab_type": "text"
      },
      "source": [
        "## Converting application_date feature to application_month and application_year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtnZxTUG58ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert str-type application date to int-type year of application\n",
        "df['application_year'] = df['application_date'].str.split('/', expand=True)[2].astype(int)\n",
        "df['application_month'] = df['application_date'].str.split('/', expand=True)[1].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BKv5pbq87QS",
        "colab_type": "text"
      },
      "source": [
        "## Converting recent_default_default_date to recent_default_year and recent_dafault_month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xchjzgDH7oTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['recent_default_default_date'] = df['recent_default_default_date'].replace(np.nan, '00/00/0000', regex=True)\n",
        "df['recent_default_year'] = df['recent_default_default_date'].str.split('/', expand=True)[2].astype(int)\n",
        "df['recent_default_month'] = df['recent_default_default_date'].str.split('/', expand=True)[1].astype(int)\n",
        "# df['recent_default_month'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX1AEV8Tv-FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['recent_default_month'].value_counts(normalize=True).sort_index().index\n",
        "y = df['recent_default_month'].value_counts(normalize=True).sort_index().values\n",
        "\n",
        "plt.xlim(1,12)\n",
        "plt.ylim(0,0.02)\n",
        "\n",
        "plt.title('Recent default month distribution')\n",
        "plt.xlabel('Month of default')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y,'g*-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFyjY--8BZgo",
        "colab_type": "text"
      },
      "source": [
        "## Adding age_of_application feature (integer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieMSSQPBmkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['age_of_application'] = df['application_year'] - df['consumer_year_of_birth']\n",
        "\n",
        "# use this \"age of application\" to validate the \"consumer year of birth\"\n",
        "# if \"age of application\" < 18, the minimum legal age of having a credit account\n",
        "# the \"consumer year of birth\" entry must be faulty. \n",
        "df['consumer_year_of_birth'].loc[df['age_of_application'] < 18] = int(9999)\n",
        "df['age_of_application'].loc[df['age_of_application'] < 18] = int(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50XCgr1qES2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the instances with -1 age_of_application\n",
        "df.drop(df[df['age_of_application'] == -1].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-bQQio2OB-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['age_of_application'].value_counts(normalize=True).sort_index().index\n",
        "y = df['age_of_application'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(-1,100)\n",
        "plt.title('Consumer Age of Application')\n",
        "plt.xlabel('Consumer Age')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y, 'g*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcsXJzCOW3cG",
        "colab_type": "text"
      },
      "source": [
        "## Adding age_of_recent_default feature (integer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GjwBFdAUrf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['age_of_recent_default'] = df['recent_default_year'] - df['consumer_year_of_birth']\n",
        "# df['age_of_recent_default'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYODky0iHMuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recent default should not happen before the year of application\n",
        "# the age of application has to be > 18 for age of recent default to be effective\n",
        "\n",
        "# For invalid entry of recent_default_default_date and consumer_year_of_birth\n",
        "df['age_of_recent_default'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(-1)\n",
        "df['recent_default_year'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(0)\n",
        "df['recent_default_month'].loc[(df['age_of_recent_default'] <df['age_of_application'])\\\n",
        "                                | (df['age_of_application'] < 18)] = int(0)\n",
        "\n",
        "# For absent recent_default_default_date \n",
        "df['age_of_recent_default'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "df['recent_default_year'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "df['recent_default_month'].loc[df['recent_default_year'] == 0] = int(0)\n",
        "\n",
        "print('Convertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZQh2iBV6Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['age_of_recent_default'].value_counts(normalize=True).sort_index().index\n",
        "y = df['age_of_recent_default'].value_counts(normalize=True).sort_index().values\n",
        "plt.xlim(20,100)\n",
        "plt.ylim(0,0.01)\n",
        "plt.title('Consumer Age of Recent Default')\n",
        "plt.xlabel('Consumer Age')\n",
        "plt.ylabel('Probability')\n",
        "plt.plot(x, y, 'g*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3KDqO-jfp0D",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning product feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF5ul58lfXpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace NaN with 'unknown'\n",
        "df['product'] = df['product'].replace(np.nan, 'unknown', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq9qS9gOeThc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shorten the tails\n",
        "x = df['product'].value_counts(normalize=True).index\n",
        "y = df['product'].value_counts(normalize=True).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvLoT-zFQ-nW",
        "colab_type": "text"
      },
      "source": [
        "## Shorten the features with heavy tails\n",
        "\n",
        "* 'product'\n",
        "* 'merchant_name'\n",
        "* 'merchant_number'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIL2Bq2dRKqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_tails_to_others(dataframe, feature, fracToConvert):\n",
        "    x = dataframe[feature].value_counts(normalize=True).index\n",
        "    y = dataframe[feature].value_counts(normalize=True).values\n",
        "\n",
        "    all_list = dataframe[feature].value_counts(normalize=True).index.tolist()\n",
        "\n",
        "    # obtain the list of value to keep\n",
        "    threshold = 1 - fracToConvert\n",
        "    current = 0.0\n",
        "    keep_list = list()\n",
        "\n",
        "    for i in range(len(y)):\n",
        "        if current >= threshold:\n",
        "            break\n",
        "        current += y[i]\n",
        "        keep_list.append(x[i])\n",
        "\n",
        "    drop_list = [x for x in all_list if x not in keep_list]\n",
        "\n",
        "    # apply keep_list\n",
        "    dataframe[feature].loc[dataframe[feature].isin(drop_list)] = 'others'\n",
        "    # print(dataframe[feature].value_counts(normalize=True))\n",
        "    # print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUKFo-PQ_b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = ['product', 'merchant_name', 'merchant_number']\n",
        "frac_dict = {'product':0.08, 'merchant_name':0.05, 'merchant_number':0.05}\n",
        "\n",
        "for name in col_names:\n",
        "    convert_tails_to_others(df, name, frac_dict[name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiU-haX6xIm",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning total_balance_outstanding feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgd-Iy4f14iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = df['total_balance_outstanding']\n",
        "\n",
        "df_tmp.replace(np.nan, '0.0', regex=True, inplace=True)\n",
        "df_tmp.replace(',', '', regex=True, inplace=True)\n",
        "df_tmp = df_tmp.astype(float)\n",
        "\n",
        "df['total_balance_outstanding'] = df_tmp\n",
        "del df_tmp\n",
        "print('Convertion complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHU-Iqef5QDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # check if everything has been converted to float-type\n",
        "# for index, value in df['total_balance_outstanding'].items():\n",
        "#     if not isinstance(value, float):\n",
        "#         print(f'{value} ----- {type(value)}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K93H3sfut1Ij",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning recent_default_default_amt feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNC2_s-yt5hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = df['recent_default_default_amt']\n",
        "\n",
        "df_tmp.replace(np.nan, '0.0', regex=True, inplace=True)\n",
        "df_tmp.replace(',', '', regex=True, inplace=True)\n",
        "df_tmp = df_tmp.astype(float)\n",
        "\n",
        "df['recent_default_default_amt'] = df_tmp\n",
        "del df_tmp\n",
        "print('Convertion complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Dt0Sy4uiRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # check if everything has been converted to float-type\n",
        "# for index, value in df['recent_default_default_amt'].items():\n",
        "#     if not isinstance(value, float):\n",
        "#         print(f'{value} ----- {type(value)}')\n",
        "# print('Assertion complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAeieMjhXlQb",
        "colab_type": "text"
      },
      "source": [
        "## Adding term_run_frac feature\n",
        "representing the fraction of terms that have been fulfilled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApB0LChyXkWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['term_run_frac'] = df['term_run'] / df['total_term']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRW1ZJcUCB6f",
        "colab_type": "text"
      },
      "source": [
        "## Adding total_month feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKzAr6wvCBhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = pd.DataFrame()\n",
        "df_tmp['total_term'] = df['total_term']\n",
        "df_tmp['total_month'] = df['total_term']\n",
        "df_tmp['freq'] = df['freq']\n",
        "\n",
        "mask = (df_tmp['freq'] == 'FN')\n",
        "df_valid = df_tmp[mask]\n",
        "\n",
        "df_tmp.loc[mask, 'total_month'] = df_valid['total_term'] / 2\n",
        "\n",
        "df['total_month'] = df_tmp['total_month']\n",
        "del df_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyGDovP3Dasn",
        "colab_type": "text"
      },
      "source": [
        "## Adding conditional mean/std features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvwm6TDODYp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conditioning for \"age_op_application\"\n",
        "df['aop_indName_mean'] = df['age_of_application'] / df.groupby(['industry_name'])['age_of_application'].transform('mean')\n",
        "df['aop_indName_stdev'] = df['age_of_application'] / df.groupby(['industry_name'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_pmtTp_mean'] = df['age_of_application'] / df.groupby(['payment_type'])['age_of_application'].transform('mean')\n",
        "df['aop_pmtTp_stdev'] = df['age_of_application'] / df.groupby(['payment_type'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_fq_mean'] = df['age_of_application'] / df.groupby(['freq'])['age_of_application'].transform('mean')\n",
        "df['aop_fq_stdev'] = df['age_of_application'] / df.groupby(['freq'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_hoId_mean'] = df['age_of_application'] / df.groupby(['homowner_ind'])['age_of_application'].transform('mean')\n",
        "df['aop_hoId_stdev'] = df['age_of_application'] / df.groupby(['homowner_ind'])['age_of_application'].transform('std')\n",
        "\n",
        "df['aop_hoCon_mean'] = df['age_of_application'] / df.groupby(['homowner_consumer'])['age_of_application'].transform('mean')\n",
        "df['aop_hoCon_stdev'] = df['age_of_application'] / df.groupby(['homowner_consumer'])['age_of_application'].transform('std')\n",
        "\n",
        "\n",
        "# Conditioning for \"purchase_amt\"\n",
        "df['pAmt_indName_mean'] = df['purchase_amt'] / df.groupby(['industry_name'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_indName_stdev'] = df['purchase_amt'] / df.groupby(['industry_name'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_pmtTp_mean'] = df['purchase_amt'] / df.groupby(['payment_type'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_pmtTp_stdev'] = df['purchase_amt'] / df.groupby(['payment_type'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_fq_mean'] = df['purchase_amt'] / df.groupby(['freq'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_fq_stdev'] = df['purchase_amt'] / df.groupby(['freq'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_hoId_mean'] = df['purchase_amt'] / df.groupby(['homowner_ind'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_hoId_stdev'] = df['purchase_amt'] / df.groupby(['homowner_ind'])['purchase_amt'].transform('std')\n",
        "\n",
        "df['pAmt_hoCon_mean'] = df['purchase_amt'] / df.groupby(['homowner_consumer'])['purchase_amt'].transform('mean')\n",
        "df['pAmt_hoCon_stdev'] = df['purchase_amt'] / df.groupby(['homowner_consumer'])['purchase_amt'].transform('std')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7r3v5VASWWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(df[df['aop_indName_stdev'].isna()].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifxjPWdSeEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check for NaN in the conditional features: \n",
        "cond_names = ['aop_indName_mean', 'aop_indName_stdev', 'aop_pmtTp_mean',\\\n",
        "              'aop_pmtTp_stdev', 'aop_fq_mean', 'aop_fq_stdev', 'aop_hoId_mean',\\\n",
        "              'aop_hoId_stdev', 'aop_hoCon_mean', 'aop_hoCon_stdev', 'pAmt_indName_mean',\\\n",
        "              'pAmt_indName_stdev', 'pAmt_pmtTp_mean', 'pAmt_pmtTp_stdev', 'pAmt_fq_mean',\\\n",
        "              'pAmt_fq_stdev', 'pAmt_hoId_mean', 'pAmt_hoId_stdev', 'pAmt_hoCon_mean', 'pAmt_hoCon_stdev']\n",
        "\n",
        "df_tmp = pd.DataFrame()\n",
        "for name in cond_names:\n",
        "    df_tmp[name] = df[name].copy()\n",
        "\n",
        "# df_tmp.head()\n",
        "msno.bar(df_tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX4sewp5DNa9",
        "colab_type": "text"
      },
      "source": [
        "## Define ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdivUjVfNekc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_recent = df[[col for col in df.columns if 'recent' in col]]\n",
        "# df_recent['defaultdate'] = df['defaultdate']\n",
        "# df_recent['consumer_id'] = df['consumer_id']\n",
        "# df_recent['defaultamount'] = df['defaultamount']\n",
        "# df_recent['contract_number'] = df['contract_number']\n",
        "# df_recent['contract_status'] = df['contract_status']\n",
        "# df_recent['expected_contract_end_date'] = df['expected_contract_end_date']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcQTEsynm_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for index, row in df_recent.iterrows():\n",
        "#     if row['recent_default_default_amt'] == 0:\n",
        "#         if isinstance(row['defaultdate'], str):\n",
        "#             print(row)\n",
        "#             print()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U_bCUCS_asC",
        "colab_type": "text"
      },
      "source": [
        "**Test outcome**\n",
        "\n",
        "* when \"recent_default_year\" == 0, there are FIVE instances that \"recent_default_default_amt\" != 0. And all FIVE instances are marked as DEFAULT by the \"contract_status\"\n",
        "\n",
        "\n",
        "* when \"recent_default_default_amt\" == 0, there are TWO instances that \"recent_default_year\" != 0. And all of the TWO instances are marked as PAIDINFULL by the \"contract_status\".\n",
        "\n",
        "    ==> both \"recent_default_year\" and \"recent_default_default_amt\" == 0 means NoDefault\n",
        "\n",
        "**Suspect bad columns:**\n",
        "\n",
        "Assumning 'recent_default_default_amt' is the indicator for the ground truth... \n",
        "\n",
        "* 'defaultdate'\n",
        "\n",
        "* 'defaultamount'\n",
        "\n",
        "* 'total_balance_outstanding'\n",
        "\n",
        "* 'recent_default_default_date' ==> 'recent_default_year' ==> 'recent_default_age'\n",
        "\n",
        "\n",
        "**Question:**\n",
        "\n",
        "Do I go back to realign 'recent_default_year' and 'recent_default_age' with the assumed ground truth???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ingd24T6LmEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# introduce the ground truth according to above analysis\n",
        "df['isDefault'] = df['recent_default_default_amt'] > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ZFyqU-_zNT",
        "colab_type": "text"
      },
      "source": [
        "## Finalising data processing and digitising categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRiOwCVFUTWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEiwLvozYjJR",
        "colab_type": "text"
      },
      "source": [
        "### Collect numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKoICV50Ylkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "\n",
        "num_names = ['purchase_amt','deposit_percent', 'age_of_application', \\\n",
        "             'gtee_rate','term_run_frac', 'total_month']\n",
        "\n",
        "# num_names = num_names + cond_names\n",
        "\n",
        "for name in num_names: \n",
        "    if name not in df.columns:\n",
        "        raise ValueError(f'column name: {name} is not valid')\n",
        "\n",
        "for name in num_names: \n",
        "    df_train[name] = df[name].copy()\n",
        "\n",
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmEMzniXU-dW",
        "colab_type": "text"
      },
      "source": [
        "### Digitise categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsWEeq8CXxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ordered_labels(df, col, order):\n",
        "    df[col] = df[col].astype('category')\n",
        "    df[col] = df[col].cat.reorder_categories(order, ordered=True)\n",
        "    df[col] = df[col].cat.codes.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgT89flKYv1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the categorical features into... \n",
        "# ordered\n",
        "ordered_features = ['application_year', 'application_month']\n",
        "ordered_dict = dict()\n",
        "for elm in ordered_features:\n",
        "    ordered_dict[elm] = df[elm].value_counts().sort_index().index\n",
        "\n",
        "# one-hot like\n",
        "oneHot_features = ['product', 'consumer_post_code', 'industry_name']\n",
        "\n",
        "# binary\n",
        "nominated_features = ['payment_type', 'freq', 'homowner_ind', 'homowner_consumer', 'isDefault']\n",
        "\n",
        "cate_names = ordered_features + nominated_features + oneHot_features\n",
        "\n",
        "# initialise encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# start encoding... \n",
        "for col in cate_names: \n",
        "    df_train[col] = df[col].copy()\n",
        "\n",
        "    # the ordered_features\n",
        "    if col in ordered_features:\n",
        "        ordered_labels(df_train, col, ordered_dict[col])\n",
        "        continue\n",
        "\n",
        "    # the one-hot like features\n",
        "    if col in oneHot_features:\n",
        "        encoder = ce.BinaryEncoder(cols=[col])\n",
        "        df_train = pd.concat([df_train, encoder.fit_transform(df_train[col])], axis=1)\n",
        "        df_train.drop(columns=[col], inplace=True)\n",
        "        continue\n",
        "\n",
        "    # other features\n",
        "    le.fit(list(df_train[col].astype(str).values))\n",
        "    df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
        "    length = df_train[col].value_counts().shape\n",
        "\n",
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94r1JkVhCcDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8JCBWUGCdDz",
        "colab_type": "text"
      },
      "source": [
        "### Rescale everything to (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6eFt8r4XArX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale numeric features to (0, 1)\n",
        "value_array = df_train.values\n",
        "col_names = df_train.columns\n",
        "# col_names = num_names + ordered_features\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "value_array_scaled = min_max_scaler.fit_transform(value_array)\n",
        "\n",
        "df_train = pd.DataFrame(value_array_scaled, columns=col_names)\n",
        "\n",
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT8QMEqkba-3",
        "colab_type": "text"
      },
      "source": [
        "### Separate input and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPb6spb6VHKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model input\n",
        "X = df_train.drop(columns=['isDefault'])\n",
        "\n",
        "# expected output\n",
        "y = df_train['isDefault']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwGymUj6c9fL",
        "colab_type": "text"
      },
      "source": [
        "### Re-sampling with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPuwDjctc9J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # initialise SMOTE sampling\n",
        "# sm = SMOTE(random_state=RAND_STATE)\n",
        "\n",
        "# # resample the training set\n",
        "# input, target = sm.fit_sample(X, y.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPJJeDDWdBIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_tmp = pd.DataFrame(input, columns=X.columns)\n",
        "# df_tmp['isDefault'] = target\n",
        "# df_tmp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv1mRVaadA2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_train = df_tmp\n",
        "# del df_tmp\n",
        "# df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUdHRcxZW_BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Re-split input/output\n",
        "\n",
        "# # model input\n",
        "# X = df_train.drop(columns=['isDefault'])\n",
        "# # expected output\n",
        "# y = df_train['isDefault']\n",
        "\n",
        "# print(X.shape)\n",
        "# print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcaZLlR3i3R6",
        "colab_type": "text"
      },
      "source": [
        "# Model Training and Validating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5jp7qKWjGHf",
        "colab_type": "text"
      },
      "source": [
        "## HyperOpt function and parameters space definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQwvOoWJjWce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Define the objective function\n",
        "    The output of this objective fnc has been set to the negative value of the mean\n",
        "    score, so that fmin() can be used to find the most suitable parameters for \n",
        "    maximum mean score.\n",
        "'''\n",
        "def objective(params):\n",
        "    time1 = time.time()\n",
        "\n",
        "    params = {\n",
        "        'max_depth'         : int(params['max_depth']),\n",
        "        'gamma'             : '{:.3f}'.format(params['gamma']),\n",
        "        'subsample'         : '{:.2f}'.format(params['subsample']),\n",
        "        'reg_alpha'         : '{:.3f}'.format(params['reg_alpha']),\n",
        "        'reg_lambda'        : '{:.3f}'.format(params['reg_lambda']),\n",
        "        'learning_rate'     : '{:.3f}'.format(params['learning_rate']),\n",
        "        'num_leaves'        : '{:.3f}'.format(params['num_leaves']),\n",
        "        'colsample_bytree'  : '{:.3f}'.format(params['colsample_bytree']),\n",
        "        'min_child_samples' : '{:.3f}'.format(params['min_child_samples']),\n",
        "        'feature_fraction'  : '{:.3f}'.format(params['feature_fraction']),\n",
        "        'bagging_fraction'  : '{:.3f}'.format(params['bagging_fraction'])\n",
        "    }\n",
        "\n",
        "    df_toprint = pd.DataFrame(params, index=[0])\n",
        "\n",
        "    print('\\n############## New Run ################')\n",
        "    print(f\"params = {df_toprint.transpose()}\")\n",
        "\n",
        "    # declair total number of folds and fold counter\n",
        "    FOLDS = 6\n",
        "    counter = 1\n",
        "\n",
        "    # instantiate the TSS model\n",
        "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RAND_STATE)\n",
        "\n",
        "    # # initialise the 0-valued array to hold the final predictions of the test set\n",
        "    # y_preds = np.zeros(y.shape[0])\n",
        "\n",
        "    # initialise the 0-valued array to hold the flag of wrong predictions for training set\n",
        "    y_oof = np.zeros(X.shape[0])\n",
        "\n",
        "    # initialise the mean score for the cross-validation\n",
        "    score_mean = 0\n",
        "    score_acc_mean = 0\n",
        "    conf_mtx = []\n",
        "\n",
        "    print(f'Training set shape: {X.shape}')\n",
        "\n",
        "    print('\\nCV - scores: ')\n",
        "\n",
        "    # Start the Training and Cross-validation loop\n",
        "    for t_idx, v_idx in skf.split(X, y):\n",
        "\n",
        "        # instantiate the XGB classifier\n",
        "        clf = xgboost.XGBClassifier(\n",
        "            n_estimators = 200, #600,\n",
        "            random_state = RAND_STATE, \n",
        "            verbose = True, \n",
        "            tree_method = 'hist', #'gpu_hist'\n",
        "            **params\n",
        "        )\n",
        "\n",
        "        # get the time series split indices\n",
        "        X_t, X_v = X.iloc[t_idx, :], X.iloc[v_idx, :]\n",
        "        y_t, y_v = y.iloc[t_idx], y.iloc[v_idx]\n",
        "\n",
        "        # Model training\n",
        "        clf.fit(X_t, y_t)\n",
        "\n",
        "        # Obtain the validation score for the fitted model\n",
        "        score = make_scorer(roc_auc_score, needs_proba=True)(clf, X_v, y_v)\n",
        "        score_mean += score\n",
        "\n",
        "        score_acc = make_scorer(accuracy_score)(clf, X_v, y_v)\n",
        "        score_acc_mean += score_acc\n",
        "\n",
        "        print(f'    {counter} :auc = {round(score, 4)}; acc = {round(score_acc, 4)}', end = \" \")\n",
        "\n",
        "        # populate the confusion matrix\n",
        "        y_pred = clf.predict(X_v)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_v, y_pred).ravel()\n",
        "        conf_mtx.append([tn, fp, fn, tp])\n",
        "\n",
        "        # advance the fold counter\n",
        "        counter += 1\n",
        "    \n",
        "    # record the time elapsed\n",
        "    time2 = time.time() - time1\n",
        "\n",
        "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
        "    gc.collect() # garbage collection\n",
        "    print(f'\\nMean ROC_AUC : {round((score_mean / FOLDS), 4)}')\n",
        "    print(f'Mean ACCURACY: {round((score_acc_mean / FOLDS), 4)}')\n",
        "\n",
        "    # compute mean confusion matrix\n",
        "    print('\\nConfusion Matrix: ')\n",
        "    i = 0\n",
        "    total = 0\n",
        "    name_list = ['TN', 'FP', 'FN', 'TP']\n",
        "    for col in zip(conf_mtx):\n",
        "        print(f'Mean {name_list[i]} = {round((np.mean(col)), 0)}')\n",
        "        i += 1\n",
        "        total += round((np.mean(col)), 0)\n",
        "    print(f'Total instance = {total}, size of validation set = {X_v.shape[0]}. ')\n",
        "\n",
        "    del X_t, X_v, y_t, y_v, clf, score, tn, fp, fn, tp\n",
        "\n",
        "    return -(score_mean / FOLDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRKlLfAw_D4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Initial guess of the objective function parameters\n",
        "'''\n",
        "\n",
        "# space = {\n",
        "#     'max_depth': hp.quniform('max_depth', 3, 18, 1),    \n",
        "#     'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "#     'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "#     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "#     'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "#     'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "#     'num_leaves': hp.choice('num_leaves', list(range(8, 100, 2))),\n",
        "#     'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "#     'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "#     'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "#     'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "# }\n",
        "\n",
        "# dummy space\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', [10]),    \n",
        "    'reg_alpha':  hp.choice('reg_alpha', [0.2]),\n",
        "    'reg_lambda': hp.choice('reg_lambda', [0.2]),\n",
        "    'learning_rate': hp.choice('learning_rate', [0.15]),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', [0.6]),\n",
        "    'gamma': hp.choice('gamma', [0.4]),\n",
        "    'num_leaves': hp.choice('num_leaves', [32]),\n",
        "    'min_child_samples': hp.choice('min_child_samples', [100]),\n",
        "    'subsample': hp.choice('subsample', [0.7]),\n",
        "    'feature_fraction': hp.choice('feature_fraction', [0.6]),\n",
        "    'bagging_fraction': hp.choice('bagging_fraction', [0.6])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_o3yrCMjLEW",
        "colab_type": "text"
      },
      "source": [
        "## Running the optimiser to train the model and obtain the best parameter combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faB9-9d5jW8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set algoritm parameters\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=1)\n",
        "\n",
        "# Print best parameters\n",
        "best_params = space_eval(space, best)\n",
        "\n",
        "print(\"BEST PARAMS: \", best_params)\n",
        "\n",
        "# make sure the 'max_depth' is an integer value\n",
        "best_params['max_depth'] = int(best_params['max_depth'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oLQWN-mjT4X",
        "colab_type": "text"
      },
      "source": [
        "# Post Processing -- Feature Importance Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyHBxgNX__Ej",
        "colab_type": "text"
      },
      "source": [
        "## Train a model with the best parameter set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGFGvJ3yjXlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = xgboost.XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    **best_params,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CbsAi9XAF5m",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfpmYu_Ejdb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get feature importance ratings\n",
        "feature_importance = clf.get_booster().get_score(importance_type='weight')\n",
        "\n",
        "# transfer teature_importance into a data frame\n",
        "keys = list(feature_importance.keys())\n",
        "values = list(feature_importance.values())\n",
        "\n",
        "df_featImp = pd.DataFrame(data=values, index=keys, columns=['score']).sort_values(by='score', ascending=False)\n",
        "\n",
        "ax = df_featImp.plot(kind='barh', figsize=(5,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUcEzNyC8FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_featImp.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElZgjIlPjqtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# terminates the current run\n",
        "raise SystemExit('Run Terminated.') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQ87b_NUrgw",
        "colab_type": "text"
      },
      "source": [
        "# Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KejW-e61ln_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "0. Original model\n",
        "================================================================================\n",
        "Mean ROC_AUC : 0.6394\n",
        "Mean ACCURACY: 0.8534\n",
        "\n",
        "purchase_amt\t        20438\n",
        "age_of_application\t    17522\n",
        "deposit_percent\t        17116\n",
        "gtee_rate\t            15754\n",
        "application_month\t    11291\n",
        "total_month\t            5404\n",
        "consumer_post_code_6\t3355\n",
        "consumer_post_code_10\t3296\n",
        "consumer_post_code_9\t3217\n",
        "application_year\t    3181\n",
        "consumer_post_code_11\t3125\n",
        "consumer_post_code_4\t3088\n",
        "consumer_post_code_5\t3042\n",
        "consumer_post_code_12\t3025\n",
        "consumer_post_code_8\t2949\n",
        "consumer_post_code_7\t2934\n",
        "consumer_post_code_3\t2724\n",
        "product_12\t            2714\n",
        "payment_type\t        2603\n",
        "product_7\t            2580\n",
        "\n",
        "\n",
        "1. SMOTE re-sampling\n",
        "================================================================================\n",
        "Mean ROC_AUC : 0.9429\n",
        "Mean ACCURACY: 0.9141\n",
        "\n",
        "purchase_amt\t        13607\n",
        "deposit_percent\t        11704\n",
        "age_of_application\t    11437\n",
        "gtee_rate\t            10769\n",
        "application_month\t    7311\n",
        "total_month\t            4150\n",
        "application_year\t    2442\n",
        "consumer_post_code_10\t2408\n",
        "consumer_post_code_6\t2292\n",
        "consumer_post_code_9\t2277\n",
        "consumer_post_code_12\t2204\n",
        "consumer_post_code_11\t2178\n",
        "consumer_post_code_7\t2163\n",
        "consumer_post_code_4\t2157\n",
        "consumer_post_code_8\t2109\n",
        "consumer_post_code_5\t2096\n",
        "payment_type\t        1914\n",
        "consumer_post_code_3\t1911\n",
        "product_12\t            1714\n",
        "product_7\t            1712\n",
        "\n",
        "\n",
        "2. Additional features\n",
        "================================================================================\n",
        "Mean ROC_AUC : 0.6382\n",
        "Mean ACCURACY: 0.8533\n",
        "\n",
        "deposit_percent\t        8545\n",
        "gtee_rate\t            8387\n",
        "pAmt_indName_mean\t    6506\n",
        "pAmt_indName_stdev\t    6334\n",
        "aop_indName_mean\t    6032\n",
        "application_month\t    5825\n",
        "aop_indName_stdev\t    5271\n",
        "pAmt_fq_mean\t        4901\n",
        "aop_pmtTp_mean\t        4129\n",
        "aop_fq_mean\t            4012\n",
        "pAmt_pmtTp_stdev\t    3978\n",
        "pAmt_fq_stdev\t        3942\n",
        "aop_pmtTp_stdev\t        3652\n",
        "purchase_amt\t        3597\n",
        "pAmt_hoId_mean\t        3295\n",
        "pAmt_pmtTp_mean\t        3180\n",
        "pAmt_hoCon_mean\t        2719\n",
        "age_of_application\t    2236\n",
        "pAmt_hoId_stdev\t        2185\n",
        "total_month\t            2180\n",
        "\n",
        "\n",
        "3. 1 + 2\n",
        "================================================================================\n",
        "Mean ROC_AUC : 0.9427\n",
        "Mean ACCURACY: 0.9135\n",
        "\n",
        "deposit_percent\t        6336\n",
        "gtee_rate\t            6306\n",
        "pAmt_indName_mean\t    4779\n",
        "pAmt_indName_stdev\t    4549\n",
        "aop_indName_mean\t    4342\n",
        "application_month\t    4104\n",
        "aop_indName_stdev\t    3835\n",
        "pAmt_fq_mean\t        3466\n",
        "aop_pmtTp_mean\t        3162\n",
        "aop_fq_mean\t            2869\n",
        "pAmt_pmtTp_stdev\t    2858\n",
        "pAmt_fq_stdev\t        2757\n",
        "purchase_amt\t        2551\n",
        "aop_pmtTp_stdev\t        2528\n",
        "pAmt_hoId_mean\t        2326\n",
        "total_month\t            2323\n",
        "pAmt_pmtTp_mean\t        2174\n",
        "age_of_application\t    1989\n",
        "pAmt_hoCon_mean\t        1890\n",
        "pAmt_hoCon_stdev\t    1764\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XKA9zcx5WrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "BEST PARAMS:  {'bagging_fraction': 0.568470595063193, 'colsample_bytree': 0.8693029173059938, 'feature_fraction': 0.6788843180864463, 'gamma': 0.28179774192830787, 'learning_rate': 0.046935737548640236, 'max_depth': 18.0, 'min_child_samples': 160, 'num_leaves': 80, 'reg_alpha': 0.15556590187576974, 'reg_lambda': 0.30452242043564615, 'subsample': 0.8}\n",
        "\n",
        "Mean ROC_AUC : 0.9473\n",
        "Mean ACCURACY: 0.9145\n",
        "\n",
        "purchase_amt\t        98014\n",
        "gtee_rate\t            95500\n",
        "pAmt_indName_mean\t    93867\n",
        "deposit_percent\t        93477\n",
        "pAmt_indName_stdev\t    82348\n",
        "application_month\t    77532\n",
        "aop_indName_mean\t    72501\n",
        "aop_indName_stdev\t    70291\n",
        "age_of_application\t    70053\n",
        "total_month\t            33514\n",
        "consumer_post_code_12\t23304\n",
        "consumer_post_code_11\t22748\n",
        "consumer_post_code_6\t22102\n",
        "consumer_post_code_9\t21838\n",
        "consumer_post_code_8\t21665\n",
        "consumer_post_code_7\t21612\n",
        "consumer_post_code_10\t21418\n",
        "consumer_post_code_5\t20726\n",
        "consumer_post_code_4\t18783\n",
        "consumer_post_code_3\t17790\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EugzBqddD2wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Original parameter range\n",
        "For Trials 1 to 3.\n",
        "---------------------------\n",
        "\n",
        "space = {\n",
        "    # The maximum depth of a tree, same as GBM.\n",
        "    # Used to control over-fitting as higher depth will allow model \n",
        "    # to learn relations very specific to a particular sample.\n",
        "    # Should be tuned using CV.\n",
        "    # Typical values: 3-10\n",
        "    'max_depth': hp.quniform('max_depth', 7, 23, 1),\n",
        "    \n",
        "    # reg_alpha: L1 regularization term. L1 regularization encourages sparsity \n",
        "    # (meaning pulling weights to 0). It can be more useful when the objective\n",
        "    # is logistic regression since you might need help with feature selection.\n",
        "    # Increasing this value will make the model more conservative. \n",
        "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "    \n",
        "    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n",
        "    # approach can be more useful in tree-models where zeroing \n",
        "    # features might not make much sense.\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    \n",
        "    # eta: Analogous to learning rate in GBM\n",
        "    # Makes the model more robust by shrinking the weights on each step\n",
        "    # Typical final values to be used: 0.01-0.2\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    \n",
        "    # colsample_bytree: Similar to max_features in GBM. Denotes the \n",
        "    # fraction of columns to be randomly samples for each tree.\n",
        "    # Typical values: 0.5-1\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "    \n",
        "    # A node is split only when the resulting split gives a positive\n",
        "    # reduction in the loss function. Gamma specifies the \n",
        "    # minimum loss reduction required to make a split.\n",
        "    # Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
        "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "    \n",
        "    # more increases accuracy, but may lead to overfitting.\n",
        "    # num_leaves: the number of leaf nodes to use. Having a large number \n",
        "    # of leaves will improve accuracy, but will also lead to overfitting.\n",
        "    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n",
        "    \n",
        "    # specifies the minimum samples per leaf node.\n",
        "    # the minimum number of samples (data) to group into a leaf. \n",
        "    # The parameter can greatly assist with overfitting: larger sample\n",
        "    # sizes per leaf will reduce overfitting (but may lead to under-fitting).\n",
        "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "    \n",
        "    # subsample: represents a fraction of the rows (observations) to be \n",
        "    # considered when building each subtree. Tianqi Chen and Carlos Guestrin\n",
        "    # in their paper A Scalable Tree Boosting System recommend \n",
        "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "    \n",
        "    # randomly select a fraction of the features.\n",
        "    # feature_fraction: controls the subsampling of features used\n",
        "    # for training (as opposed to subsampling the actual training data in \n",
        "    # the case of bagging). Smaller fractions reduce overfitting.\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "    \n",
        "    # randomly bag or subsample training data.\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "    \n",
        "    # bagging_fraction and bagging_freq: enables bagging (subsampling) \n",
        "    # of the training data. Both values need to be set for bagging to be used.\n",
        "    # The frequency controls how often (iteration) bagging is used. Smaller\n",
        "    # fractions and frequencies reduce overfitting.\n",
        "}\n",
        "'''\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDOVGanUvlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First trial\n",
        "'''\n",
        "Features Considered:\n",
        "--------------------\n",
        "num_names = ['purchase_amt','deposit_percent',\\\n",
        "             'gtee_rate','term_run_frac']\n",
        "             \n",
        "cate_names = ['product', 'contract_status','total_term',\\\n",
        "              'payment_type', 'freq', 'consumer_post_code', 'merchant_number',\\\n",
        "              'merchant_name', 'industry_name', 'homowner_ind',\\\n",
        "              'homowner_consumer', 'recent_default_year', 'recent_default_month',\\\n",
        "              'age_of_application', 'age_of_recent_default','application_year',\\\n",
        "              'application_month', 'isDefault']\n",
        "              \n",
        "Training Results: (first round)\n",
        "-----------------\n",
        "############## New Run ################\n",
        "params = {'max_depth': 12, 'gamma': '0.178', 'subsample': '0.90', 'reg_alpha': '0.135', 'reg_lambda': '0.199', 'learning_rate': '0.146', 'num_leaves': '200.000', 'colsample_bytree': '0.689', 'min_child_samples': '100.000', 'feature_fraction': '0.699', 'bagging_fraction': '0.777'}\n",
        "1 CV - score: 1.0                                     \n",
        "2 CV - score: 1.0                                     \n",
        "3 CV - score: 1.0                                     \n",
        "4 CV - score: 1.0                                     \n",
        "5 CV - score: 1.0                                     \n",
        "6 CV - score: 1.0                                     \n",
        "Total Time Run: 2.93                                  \n",
        "Mean ROC_AUC: 0.999993745011824  \n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# Second trial\n",
        "'''\n",
        "Features Considered:\n",
        "--------------------\n",
        "The following features have been removed, otherwise remain the same: \n",
        "'recent_default_year'\n",
        "'recent_default_month'\n",
        "'age_of_recent_default'\n",
        "\n",
        "As these features are observed in \"post-default\".\n",
        "\n",
        "Training Results: (best round, not finished)\n",
        "-----------------\n",
        "############## New Run ################\n",
        "params = {'max_depth': 9, 'gamma': '0.487', 'subsample': '0.20', 'reg_alpha': '0.274', 'reg_lambda': '0.125', 'learning_rate': '0.018', 'num_leaves': '190.000', 'colsample_bytree': '0.516', 'min_child_samples': '200.000', 'feature_fraction': '0.559', 'bagging_fraction': '0.642'}\n",
        "1 CV - score: 0.742\n",
        "2 CV - score: 0.7493\n",
        "3 CV - score: 0.753\n",
        "4 CV - score: 0.7566\n",
        "5 CV - score: 0.7536\n",
        "6 CV - score: 0.7513\n",
        "Total Time Run: 1.91\n",
        "Mean ROC_AUC: 0.7509450477943139\n",
        "'''\n",
        "\n",
        "\n",
        "# Third trial\n",
        "'''\n",
        "Features Considered:\n",
        "--------------------\n",
        "The following features have been removed, otherwise remain the same: \n",
        "'contract_status'\n",
        "\n",
        "\n",
        "Training Results: (best, not finished)\n",
        "-----------------\n",
        "############## New Run ################\n",
        "params = {'max_depth': 10, 'gamma': '0.381', 'subsample': '0.90', 'reg_alpha': '0.264', 'reg_lambda': '0.263', 'learning_rate': '0.048', 'num_leaves': '70.000', 'colsample_bytree': '0.626', 'min_child_samples': '200.000', 'feature_fraction': '0.669', 'bagging_fraction': '0.710'}\n",
        "1 CV - score: 0.6704\n",
        "2 CV - score: 0.6716\n",
        "3 CV - score: 0.6732\n",
        "4 CV - score: 0.6747\n",
        "5 CV - score: 0.6759\n",
        "6 CV - score: 0.6718\n",
        "Total Time Run: 2.45\n",
        "Mean ROC_AUC: 0.6729110842886276\n",
        "'''\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acmjTeIvd7uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4th Trial\n",
        "'''\n",
        "Parameter Range: \n",
        "------------------\n",
        "space = {\n",
        "    'max_depth': hp.quniform('max_depth', 3, 12, 1),    \n",
        "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n",
        "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "}\n",
        "'''\n",
        "\n",
        "'''\n",
        "Features Considered: \n",
        "--------------------\n",
        "Same as 3rd Trial\n",
        "\n",
        "Training Results: (best, finished)\n",
        "-----------------\n",
        "params =                          0\n",
        "max_depth                6\n",
        "gamma                0.368\n",
        "subsample             0.60\n",
        "reg_alpha            0.270\n",
        "reg_lambda           0.374\n",
        "learning_rate        0.076\n",
        "num_leaves          20.000\n",
        "colsample_bytree     0.680\n",
        "min_child_samples  170.000\n",
        "feature_fraction     0.497\n",
        "bagging_fraction     0.806\n",
        "\n",
        "CV - scores: \n",
        "    1 : 0.6751;\n",
        "    2 : 0.674;\n",
        "    3 : 0.674;\n",
        "    4 : 0.6774;\n",
        "    5 : 0.676;\n",
        "    6 : 0.6731;\n",
        "Total Time Run: 1.65\n",
        "Mean ROC_AUC: 0.6749405834057569\n",
        "'''\n",
        "\n",
        "'''\n",
        "Feature Importance: \n",
        "-------------------\n",
        "consumer_post_code\t    2400\n",
        "purchase_amt\t        2118\n",
        "deposit_percent\t        1754\n",
        "age_of_application\t    1634\n",
        "gtee_rate\t            1486\n",
        "merchant_name\t        1444\n",
        "merchant_number\t        1406\n",
        "product\t                1383\n",
        "application_month\t    956\n",
        "industry_name\t        871\n",
        "total_term\t            361\n",
        "payment_type\t        328\n",
        "application_year\t    273\n",
        "freq\t                261\n",
        "homowner_consumer\t    125\n",
        "homowner_ind\t        49\n",
        "term_run_frac\t        44\n",
        "'''\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFk47hXfC_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5th Trial\n",
        "'''\n",
        "Parameter Range: \n",
        "------------------\n",
        "Based on the observation from Trial-4:\n",
        "* In this attempt, reduce the range of number of leaves to (8, 32)\n",
        "* Push the upper limit of max_depth to enclose the total number of features (17)\n",
        "space = {\n",
        "    'max_depth': hp.quniform('max_depth', 3, 18, 1),    \n",
        "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "    'num_leaves': hp.choice('num_leaves', list(range(8, 32, 1))),\n",
        "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "Features Considered: \n",
        "--------------------\n",
        "Same as 3rd Trial\n",
        "\n",
        "Training Results: (best, finished)\n",
        "-----------------\n",
        "params =                          0\n",
        "max_depth                5\n",
        "gamma                0.602\n",
        "subsample             0.90\n",
        "reg_alpha            0.289\n",
        "reg_lambda           0.084\n",
        "learning_rate        0.173\n",
        "num_leaves          31.000\n",
        "colsample_bytree     0.483\n",
        "min_child_samples  210.000\n",
        "feature_fraction     0.494\n",
        "bagging_fraction     0.539\n",
        "\n",
        "CV - scores: \n",
        "    1 : 0.6749;\n",
        "    2 : 0.6751;\n",
        "    3 : 0.674;\n",
        "    4 : 0.6769;\n",
        "    5 : 0.6771;\n",
        "    6 : 0.6753;\n",
        "Total Time Run: 1.52\n",
        "Mean ROC_AUC: 0.6755379631187354\n",
        "'''\n",
        "\n",
        "'''\n",
        "Feature Importance: \n",
        "-------------------\n",
        "consumer_post_code\t    1232\n",
        "purchase_amt\t        1006\n",
        "deposit_percent\t        978\n",
        "merchant_name\t        792\n",
        "product\t                784\n",
        "age_of_application\t    764\n",
        "merchant_number\t        730\n",
        "gtee_rate\t            705\n",
        "industry_name\t        450\n",
        "application_month\t    434\n",
        "total_term\t            198\n",
        "payment_type\t        157\n",
        "application_year\t    140\n",
        "freq\t                132\n",
        "homowner_consumer\t    69\n",
        "homowner_ind\t        37\n",
        "term_run_frac\t        35\n",
        "'''\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRwCjKjyyJD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6th Trial\n",
        "'''\n",
        "Parameter Range: \n",
        "------------------\n",
        "Use the parameter range from Trial-5 with the range of num_leaves changed to (8, 100, 2)\n",
        "space = {\n",
        "    'max_depth': hp.quniform('max_depth', 3, 18, 1),    \n",
        "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "    'num_leaves': hp.choice('num_leaves', list(range(8, 100, 2))),\n",
        "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "}\n",
        "'''\n",
        "\n",
        "'''\n",
        "Features Considered: \n",
        "-----------------------\n",
        "remove feature \"merchant_name\"\n",
        "# remove merchant_name and merchant_number\n",
        "\n",
        "\n",
        "Training Results: (best, finished)\n",
        "-----------------\n",
        "params =                          0\n",
        "max_depth                7\n",
        "gamma                0.401\n",
        "subsample             0.90\n",
        "reg_alpha            0.303\n",
        "reg_lambda           0.099\n",
        "learning_rate        0.116\n",
        "num_leaves          94.000\n",
        "colsample_bytree     0.629\n",
        "min_child_samples  210.000\n",
        "feature_fraction     0.702\n",
        "bagging_fraction     0.821\n",
        "\n",
        "CV - scores: \n",
        "    1 : 0.6715;\n",
        "    2 : 0.673;\n",
        "    3 : 0.6723;\n",
        "    4 : 0.6759;\n",
        "    5 : 0.6768;\n",
        "    6 : 0.6705;\n",
        "Total Time Run: 1.93\n",
        "Mean ROC_AUC: 0.6733360373745697\n",
        "'''\n",
        "\n",
        "'''\n",
        "Feature Importance: \n",
        "-------------------\n",
        "consumer_post_code\t    4730\n",
        "purchase_amt\t        4158\n",
        "deposit_percent\t        3132\n",
        "age_of_application\t    3112\n",
        "product\t                2788\n",
        "merchant_number\t        2766\n",
        "gtee_rate\t            2706\n",
        "application_month\t    1884\n",
        "industry_name\t        1493\n",
        "total_term\t            676\n",
        "application_year\t    575\n",
        "payment_type\t        524\n",
        "freq\t                523\n",
        "homowner_consumer\t    173\n",
        "homowner_ind\t        118\n",
        "term_run_frac\t        61\n",
        "'''\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_eHrh4zxm28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7th Trial\n",
        "'''\n",
        "Parameter Range: \n",
        "------------------\n",
        "Use the parameter range from Trial-6\n",
        "space = {\n",
        "    'max_depth': hp.quniform('max_depth', 3, 18, 1),    \n",
        "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, .9),\n",
        "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
        "    'num_leaves': hp.choice('num_leaves', list(range(8, 100, 2))),\n",
        "    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n",
        "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
        "}\n",
        "'''\n",
        "\n",
        "'''\n",
        "Features Considered: \n",
        "-----------------------\n",
        "remove merchant_name and merchant_number\n",
        "\n",
        "\n",
        "Training Results: (best, finished)\n",
        "-----------------\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "Feature Importance: \n",
        "-------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGaTCyhUcaY9",
        "colab_type": "text"
      },
      "source": [
        "# Code Dump"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjl3XzidcdtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # loop through all rows to deal with bad string entries\n",
        "# # and convert all int and float entries to string\n",
        "# for index, row in df.iterrows():\n",
        "#     postCode = row['consumer_post_code']\n",
        "#     id = row['consumer_id']\n",
        "#     if isinstance(postCode, str):\n",
        "\n",
        "#         # Dealing with post codes with incorrect length\n",
        "#         if len(postCode) != 4:\n",
        "#             print(f'Bad entry detected... {postCode} -- not 4-digit entry')\n",
        "#             if postCode == '28501':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '2850'\n",
        "#             elif postCode == '2166`1':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '2166'\n",
        "#             elif postCode == '414' or postCode == 'CM144WG':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = np.nan\n",
        "\n",
        "#         # Dealing with post codes with non-decimal elements\n",
        "#         elif not postCode.strip().isdecimal():\n",
        "#             print(f'Bad entry detected... {postCode} -- non-decimal entry')\n",
        "#             if postCode == '4Q53':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '4053'\n",
        "#             elif postCode == '40/2':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '4012'\n",
        "#             elif postCode == '482O':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '4820'\n",
        "#             elif postCode == '500O':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '5000'               \n",
        "#             elif postCode == '430(':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = np.nan\n",
        "#             elif postCode == '48/7':\n",
        "#                 print(f'    consumer: {id} correcting entry')\n",
        "#                 df['consumer_post_code'].iloc[index] = '4817'   \n",
        "\n",
        "#     if isinstance(postCode, float) or isinstance(postCode, int):\n",
        "#         if pd.notna(postCode):\n",
        "#             df['consumer_post_code'].iloc[index] = str(int(postCode))\n",
        "\n",
        "# # Dealing with all nan-value entries\n",
        "# consumerid_list = df['consumer_id'].loc[df['consumer_post_code'].isna()].values\n",
        "# consumerid_list = set(consumerid_list)\n",
        "# print(consumerid_list)\n",
        "# consumerid_noPost_list = list()\n",
        "\n",
        "# for id in consumerid_list:\n",
        "#     if df['consumer_post_code'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "#         print(f'consumer: {id} has no post code info')\n",
        "#         df['consumer_post_code'].loc[df['consumer_id'] == id] = 'unknown'\n",
        "#         consumerid_noPost_list.append(id)\n",
        "#     else:\n",
        "#         possible_post_codes = df[\"consumer_post_code\"].loc[df[\"consumer_id\"] == id].values\n",
        "#         possible_post_codes = possible_post_codes[pd.notna(possible_post_codes)]\n",
        "#         print(f'consumer: {id} has the following post code: {possible_post_codes}')\n",
        "#         print(f'    applying post code to consumer: {id}')\n",
        "#         df['consumer_post_code'].loc[df['consumer_id'] == id] = str(int(possible_post_codes[0]))\n",
        "\n",
        "# print(f'Consumers without post code: {consumerid_noPost_list}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWWTMkk2Oc0a",
        "colab_type": "text"
      },
      "source": [
        "## Exploring other features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_bFaWfpx6cr",
        "colab_type": "text"
      },
      "source": [
        "### Exploring arrears amount feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriQX94hg12n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = df['arrears_amount'].value_counts(dropna=False).sort_index()\n",
        "# print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2K1Z-ujhRRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_tmp = df.loc[ df['arrears_amount'] == 0]\n",
        "# df_tmp['contract_status'].value_counts(normalize=True, dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsfUBfo9BW-2",
        "colab_type": "text"
      },
      "source": [
        "### Exploring contract_status feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym-oyOxCj-3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# '''\n",
        "# Separate the dataframe by contract status\n",
        "# '''\n",
        "\n",
        "# df_paid = df.loc[df['contract_status'] == 'PaidInFull']\n",
        "# df_default = df.loc[df['contract_status'] == 'Default']\n",
        "# df_active = df.loc[df['contract_status'] == 'Active']\n",
        "# print(df['contract_status'].value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RRPEgCcla7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the Paid-set\n",
        "# # '''\n",
        "# print(df_paid['arrears_amount'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_paid['age_of_recent_default'].value_counts(dropna=False, normalize=False).sort_index())\n",
        "# print()\n",
        "# print(df_paid['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_paid['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_paid['term_run'] / df_paid['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7q9APt-SSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the Default-set\n",
        "# # '''\n",
        "# print(df_default['arrears_amount'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['age_of_recent_default'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_values(ascending=False))\n",
        "# print()\n",
        "# print(df_default['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_default['term_run'] / df_default['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYchalKIAFhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # '''\n",
        "# # Look at the active-set\n",
        "# # '''\n",
        "# print(df_active['arrears_amount'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['age_of_recent_default'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['total_balance_outstanding'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print(df_active['defaultdate'].value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()\n",
        "# print((df_active['term_run'] / df_active['total_term']).value_counts(dropna=False, normalize=True).sort_index())\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vooTQ19Aqld",
        "colab_type": "text"
      },
      "source": [
        "**My Questions regarding the \"contract_status\" feature (ground-truth?)**\n",
        "\n",
        "* All instances in \"PaidInFull\" subset have 0.0 \"arrears_amount\", but more than 10% of the instances in this subset has a valid \"age_of_recent_default\", which suggests default did occur to these intances. All instances in this subset have NaN value for \"defaultdate\"\n",
        "\n",
        "* About 3% of the instances in \"Default\" subset have 0.0 \"arrears_amount\", which indicate default has never occured to these instances. 99.7% of this subset have a valid \"defaultdate\" entry.\n",
        "\n",
        "* \"Active\" subset has very similar behaviour when compared against \"PaidInFull\". All instances in this subset have NaN value for \"defaultdate\"\n",
        "\n",
        "**Options for ground-truth**\n",
        "\n",
        "If **True** ==> has default, **False** ==> has no default: \n",
        "\n",
        "1. **True** = \"Default\" subset and **False** = \"PaidInFull\" + \"Active\" subsets\n",
        "\n",
        "2. **True** = \"arrears_amount\" != 0, and **False** = \"arrears_amount\" == 0\n",
        "\n",
        "3. **True** = \"defaultdate\" == valid date, and **False** = NaN\n",
        "\n",
        "**According to the observations, none of the above options are fully make sense...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjQaKNxcQhVf",
        "colab_type": "text"
      },
      "source": [
        "**Meeting outcome**\n",
        "\n",
        "\n",
        "4. use the combined recent group to determine the ground truth. \n",
        "\n",
        "    i.e. when \"age_of_recent_default\", \"age_of_recent_default_cure\" and \"recent_default_amt\" are all valid ==> **DEFAULT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6PH4u7tfItC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for instances with null DoB, check if DoB of the same consumer is provided elsewhere\n",
        "# marker = '/'\n",
        "# for index, row in df.iterrows():\n",
        "#     # if the current instance DOB is not in the correct format\n",
        "#     if pd.isna(row['consumer_year_of_birth']):\n",
        "#         id = row['consumer_id']\n",
        "#         if df['consumer_year_of_birth'].loc[df['consumer_id'] == id].isnull().values.all():\n",
        "#             print(f'consumer: {id} has no DoB info')\n",
        "#             df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = '99/99/9999'        \n",
        "#         else:\n",
        "#             possibleDoBs = df[\"consumer_year_of_birth\"].loc[df[\"consumer_id\"] == id].values\n",
        "#             possibleDoBs = possibleDoBs[pd.notna(possibleDoBs)]\n",
        "#             print(f'consumer: {id} has the following BoDs: {possibleDoBs}')\n",
        "#             print(f'    applying DoB to consumer: {id}')\n",
        "#             df['consumer_year_of_birth'].loc[df['consumer_id'] == id] = str(possibleDoBs[0])\n",
        "\n",
        "# # Convert str-type DoB to int-type year of birth\n",
        "# df['consumer_year_of_birth'] = df['consumer_year_of_birth'].str.split('/', expand=True)[2].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZTLfv74lLzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # recent default should not happen before the year of application\n",
        "# # the age of application has to be > 18 for age of recent default to be effective\n",
        "# for index, row in df.iterrows():\n",
        "\n",
        "#     # try to distinguish between absent recent_default_default_date and ...\n",
        "#     if row['recent_default_year'] == 0: \n",
        "#         df['age_of_recent_default'].iloc[index] = int(0)\n",
        "#         df['recent_default_year'].iloc[index] = int(0)\n",
        "#         df['recent_default_month'].iloc[index] = int(0)\n",
        "#     # invalid entry of recent_default_default_date and consumer_year_of_birth\n",
        "#     elif row['age_of_recent_default'] < row['age_of_application'] or row['age_of_application'] < 18:\n",
        "#         df['age_of_recent_default'].iloc[index] = int(-1)\n",
        "#         df['recent_default_year'].iloc[index] = int(0)\n",
        "#         df['recent_default_month'].iloc[index] = int(0)\n",
        "\n",
        "# df['age_of_recent_default'].value_counts(normalize=False).sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}